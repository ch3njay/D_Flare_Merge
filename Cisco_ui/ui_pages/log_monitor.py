"""Cisco ç‰ˆæœ¬çš„ Log ç›£è½èˆ‡è‡ªå‹•æ¸…æ´—æ¨¡çµ„ï¼ˆStreamlit ç‰ˆï¼‰ã€‚

æ­¤æ¨¡çµ„å°‡åŸæœ¬é›†ä¸­æ–¼ PyQt5 ä»‹é¢çš„ç¨‹å¼ç¢¼é‡æ§‹ç‚º Streamlit ç›¸å®¹çš„å¯«æ³•ï¼Œ
å®Œæ•´ä¿ç•™è‡ªå‹•ç›£è½ã€è³‡æ–™æ¸…æ´—ã€æ¨¡å‹æ¨è«–èˆ‡é€šçŸ¥ä¸²æ¥çš„åŠŸèƒ½ï¼Œä¸¦è£œå¼·
åŸ·è¡Œç·’æ§ç®¡èˆ‡æ—¥èªŒå‘ˆç¾ï¼Œæ–¹ä¾¿åœ¨ç¶²é åŒ–ä»‹é¢ä¸­ç¶­è­·èˆ‡æ“´å……ã€‚
"""
from __future__ import annotations

import html
import os
import shutil
import subprocess
import sys
import tempfile
import threading
import time
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple

import pandas as pd
import streamlit as st

# Watchdog imports for improved folder monitoring
try:
    from watchdog.observers import Observer
    from watchdog.events import FileSystemEventHandler
    WATCHDOG_AVAILABLE = True
except ImportError:
    Observer = None
    FileSystemEventHandler = object
    WATCHDOG_AVAILABLE = False

# Import required modules with multiple fallback strategies
PipelineConfig = None
execute_pipeline = None
notification_pipeline = None
append_log, load_json, save_json = None, None, None

try:  # First try: package-relative imports when available
    from ..training_pipeline.config import PipelineConfig
    from ..training_pipeline.trainer import execute_pipeline
    from ..notifier import notification_pipeline
    from .utils_labels import append_log, load_json, save_json
    from ..notification_storage import get_notification_storage
except (ImportError, ValueError):
    try:  # Second try: direct imports from package directory
        from training_pipeline.config import PipelineConfig  # type: ignore[no-redef]
        from training_pipeline.trainer import execute_pipeline  # type: ignore[no-redef]
        from notifier import notification_pipeline  # type: ignore[no-redef]
        from utils_labels import append_log, load_json, save_json  # type: ignore[no-redef]
    except ImportError:
        try:  # Third try: absolute imports from Cisco_ui
            from Cisco_ui.training_pipeline.config import PipelineConfig  # type: ignore[no-redef]
            from Cisco_ui.training_pipeline.trainer import execute_pipeline  # type: ignore[no-redef]
            from Cisco_ui.notifier import notification_pipeline  # type: ignore[no-redef]
            from Cisco_ui.utils_labels import append_log, load_json, save_json  # type: ignore[no-redef]
        except ImportError:
            # Final fallback: create stub functions to prevent crashes
            import warnings
            warnings.warn("Could not import Cisco pipeline modules. Some functionality will be limited.")
            
            class PipelineConfig:  # type: ignore[no-redef]
                def __init__(self, **kwargs):
                    pass
            
            def execute_pipeline(*args, **kwargs):  # type: ignore[no-redef]
                st.error("Pipeline execution not available - missing dependencies")
                return None
            
            def notification_pipeline(*args, **kwargs):  # type: ignore[no-redef]
                st.warning("Notification pipeline not available")
                return None
            
            def append_log(*args, **kwargs):  # type: ignore[no-redef]
                return None
            
            def load_json(file_path, default=None):  # type: ignore[no-redef]
                import os
                if os.path.exists(file_path):
                    import json
                    with open(file_path, 'r', encoding='utf-8') as f:
                        return json.load(f)
                return default or {}
            
            def save_json(data, file_path):  # type: ignore[no-redef]
                import json
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)

# è¨­å®šæª”è·¯å¾‘èˆ‡é è¨­å€¼å®šç¾©
LOG_SETTINGS_FILE = "logfetcher_settings.json"
NOTIFIER_SETTINGS_FILE = "notifier_settings.txt"
DEFAULT_LOG_SETTINGS = {
    "save_dir": "",
    "binary_model_path": "",
    "model_path": "",
    "clean_csv_dir": "",
}
DEFAULT_NOTIFIER_SETTINGS = {
    "gemini_api_key": "",
    "line_channel_secret": "",
    "line_channel_access_token": "",
    "line_webhook_url": "",
    "discord_webhook_url": "",
}

PATH_BROWSER_ROOT = Path(tempfile.gettempdir()) / "df_cisco_paths"


class CiscoFileMonitorHandler(FileSystemEventHandler):
    """Ciscoå°ˆç”¨çš„æª”æ¡ˆç³»çµ±äº‹ä»¶è™•ç†å™¨ï¼Œç›£æ§ASA logæª”æ¡ˆè®ŠåŒ–ã€‚"""

    SUPPORTED_EXTS = (".csv", ".txt", ".log")
    
    def __init__(self, log_monitor: 'LogMonitor'):
        super().__init__()
        self.log_monitor = log_monitor
        self.events = []
        self.processed_files = set()
        
    def on_created(self, event):
        """æª”æ¡ˆå»ºç«‹äº‹ä»¶è™•ç†ã€‚"""
        if not event.is_directory and self._should_process_file(event.src_path):
            self.events.append(('created', event.src_path, time.time()))
            append_log(self.log_monitor.log_messages, 
                      f"ğŸ†• åµæ¸¬åˆ°æ–°æª”æ¡ˆï¼š{event.src_path}")
    
    def on_modified(self, event):
        """æª”æ¡ˆä¿®æ”¹äº‹ä»¶è™•ç†ã€‚"""
        if not event.is_directory and self._should_process_file(event.src_path):
            self.events.append(('modified', event.src_path, time.time()))
            append_log(self.log_monitor.log_messages, 
                      f"ğŸ“ æª”æ¡ˆå·²ä¿®æ”¹ï¼š{event.src_path}")
    
    def _should_process_file(self, path: str) -> bool:
        """åˆ¤æ–·æª”æ¡ˆæ˜¯å¦æ‡‰è©²è¢«è™•ç†ã€‚"""
        path_lower = path.lower()
        
        # æª¢æŸ¥æª”æ¡ˆæ“´å±•å
        if not any(path_lower.endswith(ext) for ext in self.SUPPORTED_EXTS):
            return False
            
        # éæ¿¾æ‰çµæœæª”æ¡ˆï¼ˆé¿å…è™•ç†å·²ç¶“è™•ç†éçš„æª”æ¡ˆï¼‰
        if "_result" in path_lower or "_clean" in path_lower:
            return False
            
        # æª¢æŸ¥æ˜¯å¦ç¬¦åˆASA logæª”æ¡ˆå‘½åæ¨¡å¼
        filename = os.path.basename(path_lower)
        if filename.startswith("asa_logs_") or "asa" in filename:
            return True
            
        # å…è¨±ä¸€èˆ¬çš„logæª”æ¡ˆ
        return True
    
    def get_pending_files(self) -> List[str]:
        """å–å¾—å¾…è™•ç†çš„æª”æ¡ˆæ¸…å–®ã€‚"""
        now = time.time()
        # åªè™•ç†æœ€è¿‘30ç§’å…§çš„äº‹ä»¶ï¼Œé¿å…è™•ç†éèˆŠçš„æª”æ¡ˆ
        recent_events = [
            event for event in self.events 
            if now - event[2] < 30 and event[1] not in self.processed_files
        ]
        
        # ä¾æª”æ¡ˆè·¯å¾‘åˆ†çµ„ï¼Œå–æœ€æ–°çš„äº‹ä»¶
        file_events = {}
        for event_type, file_path, timestamp in recent_events:
            if file_path not in file_events or timestamp > file_events[file_path][1]:
                file_events[file_path] = (event_type, timestamp)
        
        return list(file_events.keys())
    
    def mark_processed(self, file_path: str):
        """æ¨™è¨˜æª”æ¡ˆç‚ºå·²è™•ç†ã€‚"""
        self.processed_files.add(file_path)


class LogMonitor:
    """è² è²¬ç¶­è­·è³‡æ–™å¤¾ç›£æ§ç‹€æ…‹èˆ‡è‡ªå‹•æ¸…æ´—æµç¨‹çš„æ ¸å¿ƒç‰©ä»¶ã€‚"""

    def __init__(self) -> None:
        self.settings: Dict[str, str] = load_json(LOG_SETTINGS_FILE, DEFAULT_LOG_SETTINGS)
        self.log_messages: List[str] = []
        self.listening = False
        self.stop_event = threading.Event()
        self.monitor_thread: Optional[threading.Thread] = None
        self.socket_process: Optional[subprocess.Popen[str]] = None
        self.processed_files: Set[Tuple[str, int, float]] = set()
        self.notified_multiclass_files: Set[str] = set()
        self.last_file_checked = ""
        self.last_file_size = 0
        self.file_stable_count = 0
        self.last_processed_file = ""
        self.cleaning_lock = threading.Lock()
        self.latest_result: Optional[Dict[str, object]] = None
        self.paused = False
        self._last_folder_error: Optional[str] = None
        
        # Watchdogæ”¯æ´
        self.observer = None
        self.file_handler = None
        self.use_watchdog = WATCHDOG_AVAILABLE

    # ==== ç‹€æ…‹ç®¡ç† ====
    def update_settings(self, **kwargs: str) -> None:
        """æ›´æ–°ç›£æ§è¨­å®šä¸¦ç«‹å³å¯«å…¥è¨­å®šæª”ã€‚"""
        self.settings.update({k: v.strip() for k, v in kwargs.items()})
        save_json(LOG_SETTINGS_FILE, self.settings)
        append_log(self.log_messages, "âœ… ç›£æ§è¨­å®šå·²å„²å­˜")

    def start_listening(self) -> None:
        """å•Ÿå‹•è³‡æ–™å¤¾ç›£æ§èˆ‡èƒŒæ™¯æƒæåŸ·è¡Œç·’ã€‚"""
        if self.listening:
            append_log(self.log_messages, "âš ï¸ ç›£è½å·²åœ¨åŸ·è¡Œä¸­")
            return

        required = {
            "log å„²å­˜è³‡æ–™å¤¾": self.settings.get("save_dir", ""),
            "äºŒå…ƒæ¨¡å‹è·¯å¾‘": self.settings.get("binary_model_path", ""),
            "å¤šå…ƒæ¨¡å‹è·¯å¾‘": self.settings.get("model_path", ""),
            "æ¸…æ´—è¼¸å‡ºè³‡æ–™å¤¾": self.settings.get("clean_csv_dir", ""),
        }
        missing = [label for label, value in required.items() if not value]
        if missing:
            append_log(self.log_messages, f"â— ç¼ºå°‘å¿…è¦è¨­å®šï¼š{'ã€'.join(missing)}")
            return

        save_dir = required["log å„²å­˜è³‡æ–™å¤¾"]
        if not os.path.exists(save_dir):
            append_log(self.log_messages, f"âŒ ç›£æ§è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼š{save_dir}")
            return
        if not os.access(save_dir, os.W_OK):
            append_log(self.log_messages, f"âŒ ç„¡æ³•å¯«å…¥ç›£æ§è³‡æ–™å¤¾ï¼š{save_dir}")
            return

        self.stop_event.clear()
        
        # å˜—è©¦ä½¿ç”¨watchdogé€²è¡Œå³æ™‚ç›£æ§
        if self.use_watchdog and Observer:
            try:
                self.file_handler = CiscoFileMonitorHandler(self)
                self.observer = Observer()
                self.observer.schedule(self.file_handler, save_dir, recursive=False)
                self.observer.start()
                append_log(self.log_messages, "ğŸ” ä½¿ç”¨ watchdog é€²è¡Œå³æ™‚æª”æ¡ˆç›£æ§")
            except Exception as e:
                append_log(self.log_messages, f"âš ï¸ watchdog å•Ÿå‹•å¤±æ•—ï¼Œæ”¹ç”¨è¼ªè©¢æ¨¡å¼ï¼š{e}")
                self.use_watchdog = False
                if self.observer:
                    self.observer.stop()
                    self.observer = None
                self.file_handler = None

        # å•Ÿå‹•ç›£æ§åŸ·è¡Œç·’ï¼ˆè¼ªè©¢æ¨¡å¼ æˆ– watchdogäº‹ä»¶è™•ç†ï¼‰
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        self.listening = True
        append_log(self.log_messages, f"ğŸŸ¢ å·²å•Ÿå‹•ç›£è½ï¼Œè·¯å¾‘ï¼š{save_dir}")
        self._start_socket_process(save_dir)

    def _start_socket_process(self, save_dir: str) -> None:
        """è‹¥å°ˆå±¬ socket è…³æœ¬å­˜åœ¨å‰‡åŒæ­¥å•Ÿå‹•å­ç¨‹åºã€‚"""
        script_path = os.path.join(os.getcwd(), "socket_5.py")
        if not os.path.exists(script_path):
            append_log(self.log_messages, "â„¹ï¸ æ‰¾ä¸åˆ° socket_5.pyï¼Œåƒ…å•Ÿå‹•è³‡æ–™å¤¾ç›£æ§ã€‚")
            return
        try:
            self.socket_process = subprocess.Popen(
                [sys.executable, script_path, save_dir],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
            )
            append_log(self.log_messages, "ğŸš€ å·²å•Ÿå‹• socket_5.py å­ç¨‹åº")
            threading.Thread(target=self._capture_socket_output, daemon=True).start()
        except Exception as exc:
            append_log(self.log_messages, f"âŒ ç„¡æ³•å•Ÿå‹• socket å­ç¨‹åºï¼š{exc}")
            self.socket_process = None

    def _capture_socket_output(self) -> None:
        """æŒçºŒè®€å– socket å­ç¨‹åºè¼¸å‡ºä¸¦è¨˜éŒ„æ–¼æ—¥èªŒã€‚"""
        if not self.socket_process or not self.socket_process.stdout:
            return
        for line in self.socket_process.stdout:
            line = line.strip()
            if line:
                append_log(self.log_messages, f"[socket] {line}")
        append_log(self.log_messages, "ğŸ›‘ socket å­ç¨‹åºå·²çµæŸ")

    def stop_listening(self) -> None:
        """åœæ­¢ç›£æ§èˆ‡æ‰€æœ‰èƒŒæ™¯å·¥ä½œã€‚"""
        if not self.listening:
            append_log(self.log_messages, "âš ï¸ å°šæœªå•Ÿå‹•ç›£è½")
            return
        self.stop_event.set()
        # åœæ­¢watchdogç›£æ§
        if self.observer:
            try:
                self.observer.stop()
                self.observer.join()
                append_log(self.log_messages, "ğŸ” watchdog ç›£æ§å·²åœæ­¢")
            except Exception as exc:
                append_log(self.log_messages, f"âš ï¸ watchdog åœæ­¢å¤±æ•—ï¼š{exc}")
            finally:
                self.observer = None
                self.file_handler = None

        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=3)
        self.monitor_thread = None
        self.listening = False
        append_log(self.log_messages, "â›” å·²åœæ­¢ç›£è½")

        if self.socket_process:
            try:
                self.socket_process.terminate()
                self.socket_process.wait(timeout=3)
                append_log(self.log_messages, "ğŸ›‘ socket å­ç¨‹åºå·²çµ‚æ­¢")
            except Exception as exc:
                append_log(self.log_messages, f"âš ï¸ socket å­ç¨‹åºçµ‚æ­¢å¤±æ•—ï¼š{exc}")
            finally:
                self.socket_process = None

    # ==== è³‡æ–™å¤¾æƒæé‚è¼¯ ====
    def _monitor_loop(self) -> None:
        """èƒŒæ™¯åŸ·è¡Œç·’ï¼šè™•ç†watchdogäº‹ä»¶æˆ–åŸ·è¡Œè³‡æ–™å¤¾æƒæã€‚"""
        while not self.stop_event.is_set():
            if not self.paused:
                if self.use_watchdog and self.file_handler:
                    # ä½¿ç”¨watchdogæ™‚ï¼Œè™•ç†å¾…è™•ç†çš„æª”æ¡ˆ
                    self._process_watchdog_events()
                else:
                    # å‚³çµ±è¼ªè©¢æ¨¡å¼
                    self._inspect_folder()
            time.sleep(2)  # ç¸®çŸ­é–“éš”ä»¥æå‡watchdogéŸ¿æ‡‰é€Ÿåº¦
    
    def _process_watchdog_events(self) -> None:
        """è™•ç†watchdogåµæ¸¬åˆ°çš„æª”æ¡ˆäº‹ä»¶ã€‚"""
        if not self.file_handler:
            return
            
        pending_files = self.file_handler.get_pending_files()
        for file_path in pending_files:
            if os.path.exists(file_path):
                # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦ç©©å®šï¼ˆå¤§å°ä¸å†è®ŠåŒ–ï¼‰
                if self._is_file_stable(file_path):
                    self.last_processed_file = file_path
                    append_log(self.log_messages, f"ğŸš€ watchdog åµæ¸¬åˆ°ç©©å®šæª”æ¡ˆï¼Œæº–å‚™åˆ†æï¼š{file_path}")
                    self._launch_auto_clean(file_path)
                    self.file_handler.mark_processed(file_path)
    
    def _is_file_stable(self, file_path: str, stable_seconds: int = 3) -> bool:
        """æª¢æŸ¥æª”æ¡ˆæ˜¯å¦åœ¨æŒ‡å®šæ™‚é–“å…§å¤§å°ä¿æŒç©©å®šã€‚"""
        try:
            initial_size = os.path.getsize(file_path)
            time.sleep(stable_seconds)
            if self.stop_event.is_set():
                return False
            final_size = os.path.getsize(file_path)
            return initial_size == final_size
        except (OSError, FileNotFoundError):
            return False

    def _inspect_folder(self, manual: bool = False) -> None:
        """æƒæè³‡æ–™å¤¾ï¼Œè‹¥æ‰¾åˆ°ç©©å®šçš„æœ€æ–°æª”æ¡ˆä¾¿å•Ÿå‹•è‡ªå‹•æ¸…æ´—ã€‚"""
        folder = self.settings.get("save_dir", "").strip()
        if not folder:
            if manual:
                append_log(self.log_messages, "âš ï¸ è«‹å…ˆè¨­å®š log å„²å­˜è³‡æ–™å¤¾")
            return
        if not os.path.isdir(folder):
            if manual or self._last_folder_error != folder:
                append_log(self.log_messages, f"â— ç›£æ§è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼š{folder}")
                self._last_folder_error = folder
            return
        self._last_folder_error = None

        try:
            files = [
                f
                for f in os.listdir(folder)
                if f.endswith(".csv") and f.startswith("asa_logs_") and "_result" not in f
            ]
        except Exception as exc:
            append_log(self.log_messages, f"âŒ ç„¡æ³•è®€å–è³‡æ–™å¤¾ï¼š{exc}")
            return

        if not files:
            if manual:
                append_log(self.log_messages, "â„¹ï¸ ç›®å‰è³‡æ–™å¤¾æ²’æœ‰æ–°çš„ log æª”æ¡ˆ")
            return

        files.sort(key=lambda name: os.path.getmtime(os.path.join(folder, name)), reverse=True)
        latest_file = os.path.join(folder, files[0])
        current_size = os.path.getsize(latest_file) if os.path.exists(latest_file) else 0
        now = time.time()

        # ç§»é™¤è¶…éä¸€å°æ™‚çš„ç´€éŒ„
        self.processed_files = {
            item for item in self.processed_files if now - item[2] < 3600
        }
        if any(item[0] == latest_file and item[1] == current_size for item in self.processed_files):
            return

        if latest_file != self.last_file_checked:
            self.last_file_checked = latest_file
            self.last_file_size = current_size
            self.file_stable_count = 1
            append_log(self.log_messages, f"ğŸ†• åµæ¸¬åˆ°æ–°æª”æ¡ˆï¼š{latest_file}ï¼Œç­‰å¾…å¤§å°ç©©å®š")
            return

        if current_size == self.last_file_size:
            self.file_stable_count += 1
            append_log(self.log_messages, f"ğŸ“ˆ æª”æ¡ˆå¤§å°é€£çºŒç¬¬ {self.file_stable_count} æ¬¡ç©©å®šï¼š{current_size} bytes")
        else:
            self.file_stable_count = 1
            self.last_file_size = current_size
            append_log(self.log_messages, f"ğŸ” æª”æ¡ˆå¤§å°è®Šå‹•ç‚º {current_size}ï¼Œé‡æ–°è¨ˆæ•¸")
            return

        if self.file_stable_count >= 2:
            self.last_processed_file = latest_file
            self.processed_files.add((latest_file, current_size, now))
            append_log(self.log_messages, f"ğŸš€ æª”æ¡ˆç©©å®šï¼Œæº–å‚™è‡ªå‹•åˆ†æï¼š{latest_file}")
            self._launch_auto_clean(latest_file)

    def scan_once(self) -> None:
        """ä¾› UI æ‰‹å‹•è§¸ç™¼ä¸€æ¬¡è³‡æ–™å¤¾æƒæã€‚"""
        append_log(self.log_messages, "ğŸ” æ‰‹å‹•è§¸ç™¼è³‡æ–™å¤¾æƒæ")
        self._inspect_folder(manual=True)

    # ==== è‡ªå‹•æ¸…æ´—èˆ‡æ¨è«– ====
    def _launch_auto_clean(self, file_path: str) -> None:
        if self.cleaning_lock.locked():
            append_log(self.log_messages, "â³ å‰ä¸€æ¬¡è‡ªå‹•åˆ†æå°šæœªå®Œæˆï¼Œç•¥éæœ¬æ¬¡è§¸ç™¼")
            return
        threading.Thread(target=self._run_auto_clean, args=(file_path,), daemon=True).start()

    def _run_auto_clean(self, file_path: str) -> None:
        with self.cleaning_lock:
            append_log(self.log_messages, "âš™ï¸ é–‹å§‹åŸ·è¡Œè‡ªå‹•æ¸…æ´—èˆ‡æ¨è«–æµç¨‹")
            binary_model = self.settings.get("binary_model_path", "").strip()
            multi_model = self.settings.get("model_path", "").strip()
            output_dir = self.settings.get("clean_csv_dir", "").strip()

            missing = []
            if not binary_model:
                missing.append("äºŒå…ƒæ¨¡å‹")
            if not multi_model:
                missing.append("å¤šå…ƒæ¨¡å‹")
            if not output_dir:
                missing.append("æ¸…æ´—è¼¸å‡ºè³‡æ–™å¤¾")
            if not os.path.exists(file_path):
                missing.append("log æª”æ¡ˆ")
            if missing:
                append_log(self.log_messages, f"âŒ è‡ªå‹•åˆ†æç¼ºå°‘å¿…è¦é …ç›®ï¼š{'ã€'.join(missing)}")
                return

            os.makedirs(output_dir, exist_ok=True)

            try:
                config = PipelineConfig(
                    raw_log_path=file_path,
                    binary_model_path=binary_model,
                    multiclass_model_path=multi_model,
                    output_dir=output_dir,
                    show_progress=False,
                )
                result = execute_pipeline(config)
                self.latest_result = result
                append_log(
                    self.log_messages,
                    f"âœ… è‡ªå‹•åˆ†æå®Œæˆï¼Œè¼¸å‡º CSVï¼š{result.get('binary_output_csv', '-')}",
                )
                if result.get("binary_output_pie"):
                    append_log(
                        self.log_messages,
                        f"ğŸ“Š äºŒå…ƒåœ“é¤…åœ–ï¼š{result.get('binary_output_pie')}",
                    )
                if result.get("multiclass_output_csv"):
                    append_log(
                        self.log_messages,
                        f"ğŸ“Š å¤šå…ƒçµæœï¼š{result.get('multiclass_output_csv')}",
                    )
                self._handle_auto_notification(result)
            except Exception as exc:  # pragma: no cover - ç›¡é‡é¿å…ä¸­æ–·
                append_log(self.log_messages, f"âŒ è‡ªå‹•åˆ†æå¤±æ•—ï¼š{exc}")

    def _handle_auto_notification(self, result: Dict[str, object]) -> None:
        """æ ¹æ“šå¤šå…ƒçµæœå•Ÿå‹•é€šçŸ¥æ¨¡çµ„ã€‚"""
        multi_csv = result.get("multiclass_output_csv")
        if not multi_csv:
            append_log(self.log_messages, "â„¹ï¸ æœ¬æ‰¹æ¬¡ç„¡æ”»æ“Šæµé‡ï¼Œæœªç”¢ç”Ÿå¤šå…ƒçµæœ")
            return
        if not isinstance(multi_csv, str) or not os.path.exists(multi_csv):
            append_log(self.log_messages, f"âš ï¸ æ‰¾ä¸åˆ°å¤šå…ƒçµæœæª”æ¡ˆï¼š{multi_csv}")
            return
        if multi_csv in self.notified_multiclass_files:
            append_log(self.log_messages, "â„¹ï¸ è©²å¤šå…ƒçµæœå·²æ¨æ’­éï¼Œç•¥éé‡è¤‡é€šçŸ¥")
            return

        try:
            df = pd.read_csv(multi_csv)
        except Exception as exc:
            append_log(self.log_messages, f"âŒ è®€å–å¤šå…ƒçµæœå¤±æ•—ï¼š{exc}")
            return

        if "Severity" not in df.columns:
            append_log(self.log_messages, "â„¹ï¸ å¤šå…ƒçµæœç¼ºå°‘ Severity æ¬„ä½ï¼Œç„¡æ³•è‡ªå‹•æ¨æ’­")
            return
        # Cisco ASA: æ•¸å­—è¶Šå°è¶Šåš´é‡ï¼ˆ0-4 æ˜¯é«˜é¢¨éšªï¼‰
        # 0=ç·Šæ€¥, 1=è­¦å ±, 2=åš´é‡, 3=éŒ¯èª¤, 4=è­¦å‘Š
        if not df["Severity"].astype(str).isin(["0", "1", "2", "3", "4"]).any():
            append_log(self.log_messages, "â„¹ï¸ æœ¬æ‰¹æ¬¡ç„¡é«˜é¢¨éšªäº‹ä»¶ï¼ˆSeverity 0-4ï¼‰ï¼Œæœªå•Ÿå‹•æ¨æ’­")
            return

        settings = load_json(NOTIFIER_SETTINGS_FILE, DEFAULT_NOTIFIER_SETTINGS)
        append_log(self.log_messages, "ğŸ”” åµæ¸¬åˆ°é«˜é¢¨éšªäº‹ä»¶ï¼Œå•Ÿå‹•é€šçŸ¥æ¨¡çµ„")
        group_fields = settings.get("convergence_fields", ["source", "destination"])
        if not isinstance(group_fields, list):
            group_fields = ["source", "destination"]
        convergence_cfg = {
            "window_minutes": int(settings.get("convergence_window_minutes", 10) or 10),
            "group_fields": group_fields,
        }
        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨é€šçŸ¥
        enable_notifications = st.session_state.get("cisco_enable_notifications", True)
        enable_visualization_sync = st.session_state.get("cisco_enable_visualization_sync", True)
        
        if enable_notifications:
            notification_pipeline(
                result_csv=multi_csv,
                gemini_api_key=settings.get("gemini_api_key", ""),
                line_channel_access_token=settings.get("line_channel_access_token", ""),
                line_webhook_url=settings.get("line_webhook_url", ""),
                discord_webhook_url=settings.get("discord_webhook_url", ""),
                ui_callback=lambda msg: append_log(self.log_messages, msg),
                convergence_config=convergence_cfg,
            )
        
        # è§¸ç™¼è¦–è¦ºåŒ–åŒæ­¥æ›´æ–°
        if enable_visualization_sync:
            st.session_state.cisco_visualization_needs_update = True
            st.session_state.cisco_visualization_last_update = time.time()
            
        self.notified_multiclass_files.add(multi_csv)

    # ==== ä¾›è³‡æ–™æ¸…ç†æ¨¡çµ„å‘¼å«çš„æš«åœæ§åˆ¶ ====
    def pause(self) -> None:
        if not self.paused:
            self.paused = True
            append_log(self.log_messages, "â¸ï¸ ä¸»æµç¨‹å·²æš«åœï¼Œç­‰å¾…è³‡æ–™æ¸…ç†å®Œæˆ")

    def resume(self) -> None:
        if self.paused:
            self.paused = False
            append_log(self.log_messages, "â–¶ï¸ ä¸»æµç¨‹å·²æ¢å¾©")

    def manual_auto_clean(self, file_path: str) -> None:
        """ä¾› UI æ‰‹å‹•æŒ‡å®šæª”æ¡ˆä¸¦è§¸ç™¼è‡ªå‹•åˆ†æã€‚"""
        if not file_path:
            append_log(self.log_messages, "âš ï¸ è«‹è¼¸å…¥è¦åˆ†æçš„ log æª”æ¡ˆè·¯å¾‘")
            return
        if not os.path.exists(file_path):
            append_log(self.log_messages, f"âŒ æŒ‡å®šæª”æ¡ˆä¸å­˜åœ¨ï¼š{file_path}")
            return
        self.last_processed_file = file_path
        self._launch_auto_clean(file_path)


def get_log_monitor() -> LogMonitor:
    """å–å¾—å„²å­˜åœ¨ Streamlit session ä¸­çš„ LogMonitor å–®ä¾‹ã€‚"""
    if "cisco_log_monitor" not in st.session_state:
        st.session_state["cisco_log_monitor"] = LogMonitor()
    return st.session_state["cisco_log_monitor"]


def _persist_uploaded_model(uploaded_file, prefix: str) -> str:
    """å„²å­˜ä½¿ç”¨è€…ä¸Šå‚³çš„æ¨¡å‹æª”æ¡ˆä¸¦å›å‚³è·¯å¾‘ã€‚"""

    store = Path(tempfile.gettempdir()) / "cisco_model_store"
    store.mkdir(parents=True, exist_ok=True)
    original_name = getattr(uploaded_file, "name", f"{prefix}.pkl") or f"{prefix}.pkl"
    suffix = Path(original_name).suffix or ".pkl"
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    target_path = store / f"{prefix}_{timestamp}{suffix}"

    uploaded_file.seek(0)
    with open(target_path, "wb") as destination:
        destination.write(uploaded_file.getbuffer())

    return str(target_path)


def _render_path_preview(label: str, path: str, *, icon: str = "ğŸ“") -> None:
    """ä½¿ç”¨çµ±ä¸€æ¨£å¼å‘ˆç¾è·¯å¾‘è³‡è¨Šã€‚"""

    safe_label = html.escape(label)
    safe_icon = html.escape(icon)
    if path:
        display_path = html.escape(path)
        extra_class = ""
    else:
        display_path = "å°šæœªé¸æ“‡"
        extra_class = " path-preview--empty"

    st.markdown(
        f"""
        <div style="display: flex; align-items: center; padding: 8px 12px; background-color: #f0f2f6; border-radius: 4px; margin: 4px 0;">
            <span style="margin-right: 8px; font-size: 16px;">{safe_icon}</span>
            <div style="flex: 1;">
                <span style="font-weight: 500; color: #262730;">{safe_label}:</span>
                <span style="margin-left: 8px; color: {'#666' if not path else '#262730'};">{display_path}</span>
            </div>
        </div>
        """,
        unsafe_allow_html=True,
    )


def _persist_uploaded_manual_file(uploaded_file, monitor: LogMonitor) -> str:
    """å°‡ä½¿ç”¨è€…ä¸Šå‚³çš„æ‰‹å‹•åˆ†ææª”æ¡ˆè½åœ°ä¿å­˜ä¸¦å›å‚³è·¯å¾‘ã€‚"""

    base_dir = monitor.settings.get("save_dir", "")
    if base_dir and os.path.isdir(base_dir):
        target_dir = Path(base_dir)
    else:
        target_dir = Path(tempfile.gettempdir()) / "cisco_manual_logs"
    target_dir.mkdir(parents=True, exist_ok=True)

    timestamp = time.strftime("%Y%m%d_%H%M%S")
    original_name = Path(getattr(uploaded_file, "name", "uploaded.log") or "uploaded.log").name
    safe_name = original_name.replace(" ", "_")
    target_path = target_dir / f"manual_{timestamp}_{safe_name}"

    uploaded_file.seek(0)
    with open(target_path, "wb") as destination:
        destination.write(uploaded_file.getbuffer())

    return str(target_path)


def render_directory_selector(
    label: str,
    state_key: str,
    *,
    default: str = "",
    help_text: str | None = None,
) -> str:
    """æä¾›ä½¿ç”¨è€…ä»¥ç€è¦½æŒ‰éˆ•æˆ–æ‰‹å‹•è¼¸å…¥è¨­å®šè³‡æ–™å¤¾è·¯å¾‘ã€‚"""

    session_key = f"{state_key}_path"
    display_key = f"{session_key}_display"
    PATH_BROWSER_ROOT.mkdir(parents=True, exist_ok=True)

    if session_key not in st.session_state:
        st.session_state[session_key] = default.strip()
    if display_key not in st.session_state:
        st.session_state[display_key] = st.session_state[session_key]

    current_path = st.session_state[session_key]
    with st.container():
        st.text_input(
            label,
            value=st.session_state[display_key],
            key=display_key,
            disabled=True,
            placeholder="ä½¿ç”¨ä¸‹æ–¹ç€è¦½æŒ‰éˆ•é¸æ“‡è³‡æ–™å¤¾",
        )
        uploaded_files = st.file_uploader(
            "ç€è¦½",
            key=f"{session_key}_uploader",
            label_visibility="collapsed",
            accept_multiple_files=True,
            help=help_text
            or "é€éç€è¦½æŒ‰éˆ•æŒ‘é¸è³‡æ–™å¤¾ä¸­çš„æª”æ¡ˆï¼Œç³»çµ±æœƒå»ºç«‹å¯ç›£æ§çš„ç›®éŒ„ã€‚",
        )

    if uploaded_files:
        target_dir = PATH_BROWSER_ROOT / state_key
        if target_dir.exists():
            shutil.rmtree(target_dir)
        target_dir.mkdir(parents=True, exist_ok=True)
        for file_obj in uploaded_files:
            file_obj.seek(0)
            destination = target_dir / file_obj.name
            with open(destination, "wb") as handle:
                handle.write(file_obj.getbuffer())
        current_path = str(target_dir)
        st.session_state[session_key] = current_path
        st.session_state[display_key] = current_path
        st.success(f"å·²å»ºç«‹ç€è¦½è³‡æ–™å¤¾ï¼š{current_path}")

    manual_key = f"{session_key}_manual"
    with st.expander("éœ€è¦æ‰‹å‹•è¼¸å…¥è·¯å¾‘ï¼Ÿ", expanded=False):
        manual_value = st.text_input(
            "æ‰‹å‹•è¼¸å…¥è‡ªè¨‚è·¯å¾‘",
            value=st.session_state.get(manual_key, st.session_state[session_key]),
            key=manual_key,
        )
        manual_value = manual_value.strip()
        if manual_value and manual_value != st.session_state[session_key]:
            st.session_state[session_key] = manual_value
            st.session_state[display_key] = manual_value
            current_path = manual_value

    return st.session_state.get(session_key, current_path)


def render_manual_file_analysis(monitor: LogMonitor) -> None:
    """
    æ¸²æŸ“æ‰‹å‹•æª”æ¡ˆåˆ†æå€åŸŸ - å°ˆé–€è™•ç†å–®ä¸€æª”æ¡ˆçš„ä¸Šå‚³å’Œåˆ†æ
    """
    st.subheader("ğŸ“„ æ‰‹å‹•æª”æ¡ˆåˆ†æ")
    st.info("ä¸Šå‚³å–®ä¸€ ASA log æª”æ¡ˆé€²è¡Œå³æ™‚åˆ†æ")
    
    # æª”æ¡ˆä¸Šå‚³å€åŸŸ
    manual_path = st.session_state.get("cisco_manual_uploaded_path", monitor.last_processed_file)
    uploaded_manual = st.file_uploader(
        "é¸æ“‡è¦åˆ†æçš„ log æª”æ¡ˆ",
        type=["log", "txt", "csv"],
        accept_multiple_files=False,
        help="é€éç€è¦½æŒ‰éˆ•æŒ‘é¸ ASA logï¼Œç³»çµ±æœƒè‡ªå‹•å„²å­˜ä¸¦å¸¶å…¥åˆ†ææµç¨‹ã€‚",
        key="cisco_manual_file_uploader",
    )
    
    if uploaded_manual is not None:
        manual_path = _persist_uploaded_manual_file(uploaded_manual, monitor)
        st.session_state["cisco_manual_uploaded_path"] = manual_path
        monitor.last_processed_file = manual_path
        st.success(f"âœ… å·²æº–å‚™æª”æ¡ˆï¼š{manual_path}")

    # ç•¶å‰é¸æ“‡çš„æª”æ¡ˆé è¦½
    _render_path_preview("ç›®å‰é¸æ“‡çš„æª”æ¡ˆ", manual_path or "", icon="ğŸ“„")
    if not manual_path:
        st.caption("è«‹å…ˆé€éä¸Šæ–¹ç€è¦½æŒ‰éˆ•é¸æ“‡æ¬²åˆ†æçš„æª”æ¡ˆã€‚")

    # åˆ†ææŒ‰éˆ•
    if st.button("âš™ï¸ ç«‹å³åŸ·è¡Œåˆ†æ", use_container_width=True, type="primary"):
        if manual_path:
            with st.spinner("æ­£åœ¨åˆ†ææª”æ¡ˆ..."):
                monitor.manual_auto_clean(manual_path)
                st.success("âœ… æª”æ¡ˆåˆ†æå®Œæˆï¼")
        else:
            st.warning("è«‹å…ˆé¸æ“‡è¦åˆ†æçš„æª”æ¡ˆã€‚")


def render_folder_monitoring(monitor: LogMonitor) -> None:
    """
    æ¸²æŸ“è³‡æ–™å¤¾ç›£æ§å€åŸŸ - å°ˆé–€è™•ç†è³‡æ–™å¤¾ç›£æ§å’Œè‡ªå‹•è™•ç†
    """
    st.subheader("ğŸ“ è³‡æ–™å¤¾ç›£æ§è¨­å®š")
    st.info("è¨­å®šè³‡æ–™å¤¾è·¯å¾‘é€²è¡ŒæŒçºŒç›£æ§ï¼Œè‡ªå‹•è™•ç†æ–°å¢çš„ log æª”æ¡ˆ")
    
    # è³‡æ–™å¤¾è·¯å¾‘è¨­å®š
    current_save_dir = st.session_state.get("cisco_monitor_directory", 
                                           monitor.settings.get("save_dir", ""))
    
    col1, col2 = st.columns([3, 1])
    with col1:
        save_dir_input = st.text_input(
            "ç›£æ§è³‡æ–™å¤¾è·¯å¾‘",
            value=current_save_dir,
            help="è¼¸å…¥è¦ç›£æ§çš„è³‡æ–™å¤¾å®Œæ•´è·¯å¾‘",
            key="cisco_save_directory_input",
        )
        if save_dir_input != current_save_dir:
            st.session_state["cisco_monitor_directory"] = save_dir_input
            current_save_dir = save_dir_input
    
    with col2:
        if st.button("ğŸ  ç•¶å‰ç›®éŒ„", use_container_width=True):
            current_dir = os.getcwd()
            st.session_state["cisco_monitor_directory"] = current_dir
            st.success(f"âœ… è¨­å®šç‚ºï¼š{current_dir}")
            st.rerun()

    # è³‡æ–™å¤¾ç‹€æ…‹æª¢æŸ¥å’Œé è¦½
    if current_save_dir:
        if os.path.isdir(current_save_dir):
            _render_path_preview("ç›£æ§è³‡æ–™å¤¾", current_save_dir, icon="ğŸ“")
            
            # è³‡æ–™å¤¾å…§å®¹é è¦½
            with st.expander("ğŸ“‚ é è¦½è³‡æ–™å¤¾å…§å®¹"):
                try:
                    items = list(os.listdir(current_save_dir))
                    if items:
                        log_files = [f for f in items if f.lower().endswith(('.log', '.txt', '.csv'))]
                        other_files = [f for f in items if not f.lower().endswith(('.log', '.txt', '.csv'))]
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            if log_files:
                                st.write("ğŸ¯ **Log æª”æ¡ˆ:**")
                                for file in log_files[:10]:
                                    st.write(f"  â€¢ {file}")
                                if len(log_files) > 10:
                                    st.write(f"  ... ä»¥åŠå…¶ä»– {len(log_files) - 10} å€‹ log æª”æ¡ˆ")
                        
                        with col2:
                            if other_files:
                                st.write("ğŸ“„ **å…¶ä»–æª”æ¡ˆ:**")
                                for file in other_files[:5]:
                                    st.write(f"  â€¢ {file}")
                                if len(other_files) > 5:
                                    st.write(f"  ... ä»¥åŠå…¶ä»– {len(other_files) - 5} å€‹æª”æ¡ˆ")
                    else:
                        st.info("è³‡æ–™å¤¾æ˜¯ç©ºçš„")
                except PermissionError:
                    st.error("âŒ æ²’æœ‰æ¬Šé™å­˜å–æ­¤è³‡æ–™å¤¾")
                except Exception as e:
                    st.error(f"âŒ è®€å–è³‡æ–™å¤¾æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        else:
            st.warning("âš ï¸ è·¯å¾‘ä¸å­˜åœ¨æˆ–ä¸æ˜¯æœ‰æ•ˆçš„è³‡æ–™å¤¾")
            current_save_dir = ""
    
    # ç›£æ§æ§åˆ¶æŒ‰éˆ•
    if current_save_dir and os.path.isdir(current_save_dir):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if not monitor.listening:
                if st.button("â–¶ï¸ é–‹å§‹ç›£æ§", use_container_width=True, type="primary"):
                    monitor.update_settings(save_dir=current_save_dir)
                    monitor.start_listening()
                    st.success("âœ… å·²é–‹å§‹ç›£æ§è³‡æ–™å¤¾")
                    st.rerun()
            else:
                if st.button("â¸ï¸ æš«åœç›£æ§", use_container_width=True):
                    monitor.pause()
                    st.info("â¸ï¸ ç›£æ§å·²æš«åœ")
                    st.rerun()
        
        with col2:
            if monitor.listening:
                if st.button("â¹ï¸ åœæ­¢ç›£æ§", use_container_width=True):
                    monitor.stop_listening()
                    st.info("â¹ï¸ ç›£æ§å·²åœæ­¢")
                    st.rerun()
            
        with col3:
            if st.button("ğŸ” æ‰‹å‹•æƒæä¸€æ¬¡", use_container_width=True):
                if monitor.listening:
                    monitor.scan_once()
                else:
                    # å³ä½¿æœªç›£æ§ä¹Ÿå…è¨±æ‰‹å‹•æƒæ
                    monitor.update_settings(save_dir=current_save_dir)
                    monitor.scan_once()
    else:
        st.caption("è«‹å…ˆè¨­å®šæœ‰æ•ˆçš„è³‡æ–™å¤¾è·¯å¾‘ä»¥å•Ÿç”¨ç›£æ§åŠŸèƒ½")


def render_model_settings(monitor: LogMonitor) -> None:
    """
    æ¸²æŸ“æ¨¡å‹è¨­å®šå€åŸŸ
    """
    st.subheader("ğŸ§  æ¨¡å‹è¨­å®š")
    
    with st.form("model_settings"):
        # è¼¸å‡ºè³‡æ–™å¤¾è¨­å®š
        current_clean_dir = st.session_state.get("cisco_clean_dir", 
                                                 monitor.settings.get("clean_csv_dir", ""))
        clean_dir = st.text_input(
            "æ¸…æ´—è¼¸å‡ºè³‡æ–™å¤¾",
            value=current_clean_dir,
            help="è¨­å®šåˆ†æçµæœçš„è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘",
            key="cisco_clean_dir_input"
        )

        st.markdown("##### æ¨¡å‹æª”æ¡ˆ")
        current_binary = st.session_state.get(
            "cisco_binary_model_path", monitor.settings.get("binary_model_path", "")
        )
        binary_upload = st.file_uploader(
            "é¸æ“‡äºŒå…ƒæ¨¡å‹æª” (.pkl/.joblib)",
            type=["pkl", "joblib"],
            key="cisco_binary_model_upload",
            help="é€éç€è¦½æŒ‰éˆ•æŒ‘é¸äºŒå…ƒåˆ†é¡æ¨¡å‹ï¼Œå°‡è‡ªå‹•å„²å­˜ä¸¦å¥—ç”¨æ–¼ç›£æ§æµç¨‹ã€‚",
        )
        _render_path_preview("ç›®å‰ä½¿ç”¨çš„äºŒå…ƒæ¨¡å‹", current_binary, icon="ğŸ§ ")

        current_multi = st.session_state.get(
            "cisco_multi_model_path", monitor.settings.get("model_path", "")
        )
        multi_upload = st.file_uploader(
            "é¸æ“‡å¤šå…ƒæ¨¡å‹æª” (.pkl/.joblib)",
            type=["pkl", "joblib"],
            key="cisco_multi_model_upload",
            help="é€éç€è¦½æŒ‰éˆ•æŒ‘é¸å¤šå…ƒåˆ†é¡æ¨¡å‹ï¼Œå°‡è‡ªå‹•å„²å­˜ä¸¦å¥—ç”¨æ–¼ç›£æ§æµç¨‹ã€‚",
        )
        _render_path_preview("ç›®å‰ä½¿ç”¨çš„å¤šå…ƒæ¨¡å‹", current_multi, icon="ğŸ—‚ï¸")

        # ä½¿ç”¨åˆ—ä¾†ç½®ä¸­å°é½ŠæŒ‰éˆ•
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            submitted = st.form_submit_button("ğŸ’¾ å„²å­˜æ¨¡å‹è¨­å®š", use_container_width=True)
        if submitted:
            binary_path = current_binary
            multi_path = current_multi
            if binary_upload is not None:
                binary_path = _persist_uploaded_model(binary_upload, "binary_model")
            if multi_upload is not None:
                multi_path = _persist_uploaded_model(multi_upload, "multiclass_model")

            st.session_state["cisco_binary_model_path"] = binary_path
            st.session_state["cisco_multi_model_path"] = multi_path
            st.session_state["cisco_clean_dir"] = clean_dir
            monitor.update_settings(
                binary_model_path=binary_path,
                model_path=multi_path,
                clean_csv_dir=clean_dir,
            )
            st.success("âœ… æ¨¡å‹è¨­å®šå·²æ›´æ–°")


def render_status_and_logs(monitor: LogMonitor) -> None:
    """
    æ¸²æŸ“ç‹€æ…‹é¡¯ç¤ºå’Œæ—¥èªŒå€åŸŸ
    """
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š ç›£æ§ç‹€æ…‹")
        status = "ğŸŸ¢ ç›£è½ä¸­" if monitor.listening else "â›” å·²åœæ­¢"
        st.markdown(f"ç›®å‰ç‹€æ…‹ï¼š**{status}**")
        
        # é¡¯ç¤ºç›£æ§è³‡æ–™å¤¾
        monitor_dir = st.session_state.get("cisco_monitor_directory", "")
        if monitor_dir:
            st.caption(f"ç›£æ§è³‡æ–™å¤¾ï¼š{monitor_dir}")
    
    with col2:
        st.subheader("ğŸ”„ æœ€æ–°çµæœ")
        if monitor.latest_result:
            st.success("é¡¯ç¤ºæœ€æ–°è‡ªå‹•åˆ†æçµæœï¼š")
            with st.expander("æŸ¥çœ‹è©³ç´°çµæœ", expanded=False):
                st.json(monitor.latest_result)
        else:
            st.info("å°šç„¡åˆ†æçµæœ")

    st.subheader("ğŸ“ åŸ·è¡Œæ—¥èªŒ")
    if monitor.log_messages:
        recent_logs = monitor.log_messages[-20:]  # é¡¯ç¤ºæœ€è¿‘20æ¢æ—¥èªŒ
        log_text = "\n".join(recent_logs)
        st.text_area(
            "åŸ·è¡Œæ—¥èªŒ",
            value=log_text,
            height=200,
            key="cisco_log_display"
        )
        
        if len(monitor.log_messages) > 20:
            if st.button("ğŸ“œ é¡¯ç¤ºå®Œæ•´æ—¥èªŒ"):
                st.text_area(
                    "å®Œæ•´åŸ·è¡Œæ—¥èªŒ",
                    value="\n".join(monitor.log_messages),
                    height=400,
                    key="cisco_full_log_display"
                )
    else:
        st.info("æš«ç„¡åŸ·è¡Œæ—¥èªŒ")


def app() -> None:
    """Streamlit ç‰ˆçš„ Log æ“·å–é é¢ - é‡æ§‹ç‰ˆæœ¬ï¼Œæ¸…æ¥šåˆ†é›¢å–®æª”æ¡ˆåˆ†æå’Œè³‡æ–™å¤¾ç›£æ§åŠŸèƒ½ã€‚"""
    monitor = get_log_monitor()

    st.title("ğŸ“„ Cisco Log æ“·å–èˆ‡è‡ªå‹•åˆ†æ")
    st.markdown("æ­¤é é¢æä¾›å–®æª”æ¡ˆåˆ†æå’Œè³‡æ–™å¤¾ç›£æ§å…©ç¨®æ–¹å¼è™•ç† ASA log")

    # åˆå§‹åŒ–session state
    st.session_state.setdefault("cisco_binary_model_path", monitor.settings.get("binary_model_path", ""))
    st.session_state.setdefault("cisco_multi_model_path", monitor.settings.get("model_path", ""))
    st.session_state.setdefault("cisco_clean_dir", monitor.settings.get("clean_csv_dir", ""))

    # ä½¿ç”¨tabä¾†åˆ†é›¢ä¸åŒåŠŸèƒ½å€åŸŸ
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“„ æ‰‹å‹•æª”æ¡ˆåˆ†æ", 
        "ğŸ“ è³‡æ–™å¤¾ç›£æ§", 
        "ğŸ§  æ¨¡å‹è¨­å®š", 
        "ğŸ“Š ç‹€æ…‹èˆ‡æ—¥èªŒ"
    ])
    
    with tab1:
        render_manual_file_analysis(monitor)
    
    with tab2:
        render_folder_monitoring(monitor)
    
    with tab3:
        render_model_settings(monitor)
    
    with tab4:
        render_status_and_logs(monitor)
