"""Cisco ç‰ˆæœ¬çš„ Log ç›£è½èˆ‡è‡ªå‹•æ¸…æ´—æ¨¡çµ„ï¼ˆStreamlit ç‰ˆï¼‰ã€‚

æ­¤æ¨¡çµ„å°‡åŸæœ¬é›†ä¸­æ–¼ PyQt5 ä»‹é¢çš„ç¨‹å¼ç¢¼é‡æ§‹ç‚º Streamlit ç›¸å®¹çš„å¯«æ³•ï¼Œ
å®Œæ•´ä¿ç•™è‡ªå‹•ç›£è½ã€è³‡æ–™æ¸…æ´—ã€æ¨¡å‹æ¨è«–èˆ‡é€šçŸ¥ä¸²æ¥çš„åŠŸèƒ½ï¼Œä¸¦è£œå¼·
åŸ·è¡Œç·’æ§ç®¡èˆ‡æ—¥èªŒå‘ˆç¾ï¼Œæ–¹ä¾¿åœ¨ç¶²é åŒ–ä»‹é¢ä¸­ç¶­è­·èˆ‡æ“´å……ã€‚
"""
from __future__ import annotations

import os
import subprocess
import sys
import threading
import time
from typing import Dict, List, Optional, Set, Tuple

import pandas as pd
import streamlit as st

try:  # Prefer package-relative imports when available
    from ..training_pipeline.config import PipelineConfig
    from ..training_pipeline.trainer import execute_pipeline
    from ..notifier import notification_pipeline
    from ..utils_labels import append_log, load_json, save_json
except (ImportError, ValueError):  # Support running within the package directory directly
    from training_pipeline.config import PipelineConfig  # type: ignore[no-redef]
    from training_pipeline.trainer import execute_pipeline  # type: ignore[no-redef]
    from notifier import notification_pipeline  # type: ignore[no-redef]
    from utils_labels import append_log, load_json, save_json  # type: ignore[no-redef]

# è¨­å®šæª”è·¯å¾‘èˆ‡é è¨­å€¼å®šç¾©
LOG_SETTINGS_FILE = "logfetcher_settings.json"
NOTIFIER_SETTINGS_FILE = "notifier_settings.txt"
DEFAULT_LOG_SETTINGS = {
    "save_dir": "",
    "binary_model_path": "",
    "model_path": "",
    "clean_csv_dir": "",
}
DEFAULT_NOTIFIER_SETTINGS = {
    "gemini_api_key": "",
    "line_channel_secret": "",
    "line_channel_access_token": "",
    "line_webhook_url": "",
    "discord_webhook_url": "",
}


class LogMonitor:
    """è² è²¬ç¶­è­·è³‡æ–™å¤¾ç›£æ§ç‹€æ…‹èˆ‡è‡ªå‹•æ¸…æ´—æµç¨‹çš„æ ¸å¿ƒç‰©ä»¶ã€‚"""

    def __init__(self) -> None:
        self.settings: Dict[str, str] = load_json(LOG_SETTINGS_FILE, DEFAULT_LOG_SETTINGS)
        self.log_messages: List[str] = []
        self.listening = False
        self.stop_event = threading.Event()
        self.monitor_thread: Optional[threading.Thread] = None
        self.socket_process: Optional[subprocess.Popen[str]] = None
        self.processed_files: Set[Tuple[str, int, float]] = set()
        self.notified_multiclass_files: Set[str] = set()
        self.last_file_checked = ""
        self.last_file_size = 0
        self.file_stable_count = 0
        self.last_processed_file = ""
        self.cleaning_lock = threading.Lock()
        self.latest_result: Optional[Dict[str, object]] = None
        self.paused = False
        self._last_folder_error: Optional[str] = None

    # ==== ç‹€æ…‹ç®¡ç† ====
    def update_settings(self, **kwargs: str) -> None:
        """æ›´æ–°ç›£æ§è¨­å®šä¸¦ç«‹å³å¯«å…¥è¨­å®šæª”ã€‚"""
        self.settings.update({k: v.strip() for k, v in kwargs.items()})
        save_json(LOG_SETTINGS_FILE, self.settings)
        append_log(self.log_messages, "âœ… ç›£æ§è¨­å®šå·²å„²å­˜")

    def start_listening(self) -> None:
        """å•Ÿå‹•è³‡æ–™å¤¾ç›£æ§èˆ‡èƒŒæ™¯æƒæåŸ·è¡Œç·’ã€‚"""
        if self.listening:
            append_log(self.log_messages, "âš ï¸ ç›£è½å·²åœ¨åŸ·è¡Œä¸­")
            return

        required = {
            "log å„²å­˜è³‡æ–™å¤¾": self.settings.get("save_dir", ""),
            "äºŒå…ƒæ¨¡å‹è·¯å¾‘": self.settings.get("binary_model_path", ""),
            "å¤šå…ƒæ¨¡å‹è·¯å¾‘": self.settings.get("model_path", ""),
            "æ¸…æ´—è¼¸å‡ºè³‡æ–™å¤¾": self.settings.get("clean_csv_dir", ""),
        }
        missing = [label for label, value in required.items() if not value]
        if missing:
            append_log(self.log_messages, f"â— ç¼ºå°‘å¿…è¦è¨­å®šï¼š{'ã€'.join(missing)}")
            return

        save_dir = required["log å„²å­˜è³‡æ–™å¤¾"]
        if not os.path.exists(save_dir):
            append_log(self.log_messages, f"âŒ ç›£æ§è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼š{save_dir}")
            return
        if not os.access(save_dir, os.W_OK):
            append_log(self.log_messages, f"âŒ ç„¡æ³•å¯«å…¥ç›£æ§è³‡æ–™å¤¾ï¼š{save_dir}")
            return

        self.stop_event.clear()
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        self.listening = True
        append_log(self.log_messages, f"ğŸŸ¢ å·²å•Ÿå‹•ç›£è½ï¼Œè·¯å¾‘ï¼š{save_dir}")
        self._start_socket_process(save_dir)

    def _start_socket_process(self, save_dir: str) -> None:
        """è‹¥å°ˆå±¬ socket è…³æœ¬å­˜åœ¨å‰‡åŒæ­¥å•Ÿå‹•å­ç¨‹åºã€‚"""
        script_path = os.path.join(os.getcwd(), "socket_5.py")
        if not os.path.exists(script_path):
            append_log(self.log_messages, "â„¹ï¸ æ‰¾ä¸åˆ° socket_5.pyï¼Œåƒ…å•Ÿå‹•è³‡æ–™å¤¾ç›£æ§ã€‚")
            return
        try:
            self.socket_process = subprocess.Popen(
                [sys.executable, script_path, save_dir],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
            )
            append_log(self.log_messages, "ğŸš€ å·²å•Ÿå‹• socket_5.py å­ç¨‹åº")
            threading.Thread(target=self._capture_socket_output, daemon=True).start()
        except Exception as exc:
            append_log(self.log_messages, f"âŒ ç„¡æ³•å•Ÿå‹• socket å­ç¨‹åºï¼š{exc}")
            self.socket_process = None

    def _capture_socket_output(self) -> None:
        """æŒçºŒè®€å– socket å­ç¨‹åºè¼¸å‡ºä¸¦è¨˜éŒ„æ–¼æ—¥èªŒã€‚"""
        if not self.socket_process or not self.socket_process.stdout:
            return
        for line in self.socket_process.stdout:
            line = line.strip()
            if line:
                append_log(self.log_messages, f"[socket] {line}")
        append_log(self.log_messages, "ğŸ›‘ socket å­ç¨‹åºå·²çµæŸ")

    def stop_listening(self) -> None:
        """åœæ­¢ç›£æ§èˆ‡æ‰€æœ‰èƒŒæ™¯å·¥ä½œã€‚"""
        if not self.listening:
            append_log(self.log_messages, "âš ï¸ å°šæœªå•Ÿå‹•ç›£è½")
            return
        self.stop_event.set()
        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=3)
        self.monitor_thread = None
        self.listening = False
        append_log(self.log_messages, "â›” å·²åœæ­¢ç›£è½")

        if self.socket_process:
            try:
                self.socket_process.terminate()
                self.socket_process.wait(timeout=3)
                append_log(self.log_messages, "ğŸ›‘ socket å­ç¨‹åºå·²çµ‚æ­¢")
            except Exception as exc:
                append_log(self.log_messages, f"âš ï¸ socket å­ç¨‹åºçµ‚æ­¢å¤±æ•—ï¼š{exc}")
            finally:
                self.socket_process = None

    # ==== è³‡æ–™å¤¾æƒæé‚è¼¯ ====
    def _monitor_loop(self) -> None:
        """èƒŒæ™¯åŸ·è¡Œç·’ï¼šæ¯ 5 ç§’æƒæä¸€æ¬¡è³‡æ–™å¤¾ã€‚"""
        while not self.stop_event.is_set():
            if not self.paused:
                self._inspect_folder()
            time.sleep(5)

    def _inspect_folder(self, manual: bool = False) -> None:
        """æƒæè³‡æ–™å¤¾ï¼Œè‹¥æ‰¾åˆ°ç©©å®šçš„æœ€æ–°æª”æ¡ˆä¾¿å•Ÿå‹•è‡ªå‹•æ¸…æ´—ã€‚"""
        folder = self.settings.get("save_dir", "").strip()
        if not folder:
            if manual:
                append_log(self.log_messages, "âš ï¸ è«‹å…ˆè¨­å®š log å„²å­˜è³‡æ–™å¤¾")
            return
        if not os.path.isdir(folder):
            if manual or self._last_folder_error != folder:
                append_log(self.log_messages, f"â— ç›£æ§è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼š{folder}")
                self._last_folder_error = folder
            return
        self._last_folder_error = None

        try:
            files = [
                f
                for f in os.listdir(folder)
                if f.endswith(".csv") and f.startswith("asa_logs_") and "_result" not in f
            ]
        except Exception as exc:
            append_log(self.log_messages, f"âŒ ç„¡æ³•è®€å–è³‡æ–™å¤¾ï¼š{exc}")
            return

        if not files:
            if manual:
                append_log(self.log_messages, "â„¹ï¸ ç›®å‰è³‡æ–™å¤¾æ²’æœ‰æ–°çš„ log æª”æ¡ˆ")
            return

        files.sort(key=lambda name: os.path.getmtime(os.path.join(folder, name)), reverse=True)
        latest_file = os.path.join(folder, files[0])
        current_size = os.path.getsize(latest_file) if os.path.exists(latest_file) else 0
        now = time.time()

        # ç§»é™¤è¶…éä¸€å°æ™‚çš„ç´€éŒ„
        self.processed_files = {
            item for item in self.processed_files if now - item[2] < 3600
        }
        if any(item[0] == latest_file and item[1] == current_size for item in self.processed_files):
            return

        if latest_file != self.last_file_checked:
            self.last_file_checked = latest_file
            self.last_file_size = current_size
            self.file_stable_count = 1
            append_log(self.log_messages, f"ğŸ†• åµæ¸¬åˆ°æ–°æª”æ¡ˆï¼š{latest_file}ï¼Œç­‰å¾…å¤§å°ç©©å®š")
            return

        if current_size == self.last_file_size:
            self.file_stable_count += 1
            append_log(self.log_messages, f"ğŸ“ˆ æª”æ¡ˆå¤§å°é€£çºŒç¬¬ {self.file_stable_count} æ¬¡ç©©å®šï¼š{current_size} bytes")
        else:
            self.file_stable_count = 1
            self.last_file_size = current_size
            append_log(self.log_messages, f"ğŸ” æª”æ¡ˆå¤§å°è®Šå‹•ç‚º {current_size}ï¼Œé‡æ–°è¨ˆæ•¸")
            return

        if self.file_stable_count >= 2:
            self.last_processed_file = latest_file
            self.processed_files.add((latest_file, current_size, now))
            append_log(self.log_messages, f"ğŸš€ æª”æ¡ˆç©©å®šï¼Œæº–å‚™è‡ªå‹•åˆ†æï¼š{latest_file}")
            self._launch_auto_clean(latest_file)

    def scan_once(self) -> None:
        """ä¾› UI æ‰‹å‹•è§¸ç™¼ä¸€æ¬¡è³‡æ–™å¤¾æƒæã€‚"""
        append_log(self.log_messages, "ğŸ” æ‰‹å‹•è§¸ç™¼è³‡æ–™å¤¾æƒæ")
        self._inspect_folder(manual=True)

    # ==== è‡ªå‹•æ¸…æ´—èˆ‡æ¨è«– ====
    def _launch_auto_clean(self, file_path: str) -> None:
        if self.cleaning_lock.locked():
            append_log(self.log_messages, "â³ å‰ä¸€æ¬¡è‡ªå‹•åˆ†æå°šæœªå®Œæˆï¼Œç•¥éæœ¬æ¬¡è§¸ç™¼")
            return
        threading.Thread(target=self._run_auto_clean, args=(file_path,), daemon=True).start()

    def _run_auto_clean(self, file_path: str) -> None:
        with self.cleaning_lock:
            append_log(self.log_messages, "âš™ï¸ é–‹å§‹åŸ·è¡Œè‡ªå‹•æ¸…æ´—èˆ‡æ¨è«–æµç¨‹")
            binary_model = self.settings.get("binary_model_path", "").strip()
            multi_model = self.settings.get("model_path", "").strip()
            output_dir = self.settings.get("clean_csv_dir", "").strip()

            missing = []
            if not binary_model:
                missing.append("äºŒå…ƒæ¨¡å‹")
            if not multi_model:
                missing.append("å¤šå…ƒæ¨¡å‹")
            if not output_dir:
                missing.append("æ¸…æ´—è¼¸å‡ºè³‡æ–™å¤¾")
            if not os.path.exists(file_path):
                missing.append("log æª”æ¡ˆ")
            if missing:
                append_log(self.log_messages, f"âŒ è‡ªå‹•åˆ†æç¼ºå°‘å¿…è¦é …ç›®ï¼š{'ã€'.join(missing)}")
                return

            os.makedirs(output_dir, exist_ok=True)

            try:
                config = PipelineConfig(
                    raw_log_path=file_path,
                    binary_model_path=binary_model,
                    multiclass_model_path=multi_model,
                    output_dir=output_dir,
                    show_progress=False,
                )
                result = execute_pipeline(config)
                self.latest_result = result
                append_log(
                    self.log_messages,
                    f"âœ… è‡ªå‹•åˆ†æå®Œæˆï¼Œè¼¸å‡º CSVï¼š{result.get('binary_output_csv', '-')}",
                )
                if result.get("binary_output_pie"):
                    append_log(
                        self.log_messages,
                        f"ğŸ“Š äºŒå…ƒåœ“é¤…åœ–ï¼š{result.get('binary_output_pie')}",
                    )
                if result.get("multiclass_output_csv"):
                    append_log(
                        self.log_messages,
                        f"ğŸ“Š å¤šå…ƒçµæœï¼š{result.get('multiclass_output_csv')}",
                    )
                self._handle_auto_notification(result)
            except Exception as exc:  # pragma: no cover - ç›¡é‡é¿å…ä¸­æ–·
                append_log(self.log_messages, f"âŒ è‡ªå‹•åˆ†æå¤±æ•—ï¼š{exc}")

    def _handle_auto_notification(self, result: Dict[str, object]) -> None:
        """æ ¹æ“šå¤šå…ƒçµæœå•Ÿå‹•é€šçŸ¥æ¨¡çµ„ã€‚"""
        multi_csv = result.get("multiclass_output_csv")
        if not multi_csv:
            append_log(self.log_messages, "â„¹ï¸ æœ¬æ‰¹æ¬¡ç„¡æ”»æ“Šæµé‡ï¼Œæœªç”¢ç”Ÿå¤šå…ƒçµæœ")
            return
        if not isinstance(multi_csv, str) or not os.path.exists(multi_csv):
            append_log(self.log_messages, f"âš ï¸ æ‰¾ä¸åˆ°å¤šå…ƒçµæœæª”æ¡ˆï¼š{multi_csv}")
            return
        if multi_csv in self.notified_multiclass_files:
            append_log(self.log_messages, "â„¹ï¸ è©²å¤šå…ƒçµæœå·²æ¨æ’­éï¼Œç•¥éé‡è¤‡é€šçŸ¥")
            return

        try:
            df = pd.read_csv(multi_csv)
        except Exception as exc:
            append_log(self.log_messages, f"âŒ è®€å–å¤šå…ƒçµæœå¤±æ•—ï¼š{exc}")
            return

        if "Severity" not in df.columns:
            append_log(self.log_messages, "â„¹ï¸ å¤šå…ƒçµæœç¼ºå°‘ Severity æ¬„ä½ï¼Œç„¡æ³•è‡ªå‹•æ¨æ’­")
            return
        if not df["Severity"].astype(str).isin(["1", "2", "3"]).any():
            append_log(self.log_messages, "â„¹ï¸ æœ¬æ‰¹æ¬¡ç„¡é«˜é¢¨éšªäº‹ä»¶ï¼Œæœªå•Ÿå‹•æ¨æ’­")
            return

        settings = load_json(NOTIFIER_SETTINGS_FILE, DEFAULT_NOTIFIER_SETTINGS)
        append_log(self.log_messages, "ğŸ”” åµæ¸¬åˆ°é«˜é¢¨éšªäº‹ä»¶ï¼Œå•Ÿå‹•é€šçŸ¥æ¨¡çµ„")
        notification_pipeline(
            result_csv=multi_csv,
            gemini_api_key=settings.get("gemini_api_key", ""),
            line_channel_access_token=settings.get("line_channel_access_token", ""),
            line_webhook_url=settings.get("line_webhook_url", ""),
            discord_webhook_url=settings.get("discord_webhook_url", ""),
            ui_callback=lambda msg: append_log(self.log_messages, msg),
        )
        self.notified_multiclass_files.add(multi_csv)

    # ==== ä¾›è³‡æ–™æ¸…ç†æ¨¡çµ„å‘¼å«çš„æš«åœæ§åˆ¶ ====
    def pause(self) -> None:
        if not self.paused:
            self.paused = True
            append_log(self.log_messages, "â¸ï¸ ä¸»æµç¨‹å·²æš«åœï¼Œç­‰å¾…è³‡æ–™æ¸…ç†å®Œæˆ")

    def resume(self) -> None:
        if self.paused:
            self.paused = False
            append_log(self.log_messages, "â–¶ï¸ ä¸»æµç¨‹å·²æ¢å¾©")

    def manual_auto_clean(self, file_path: str) -> None:
        """ä¾› UI æ‰‹å‹•æŒ‡å®šæª”æ¡ˆä¸¦è§¸ç™¼è‡ªå‹•åˆ†æã€‚"""
        if not file_path:
            append_log(self.log_messages, "âš ï¸ è«‹è¼¸å…¥è¦åˆ†æçš„ log æª”æ¡ˆè·¯å¾‘")
            return
        if not os.path.exists(file_path):
            append_log(self.log_messages, f"âŒ æŒ‡å®šæª”æ¡ˆä¸å­˜åœ¨ï¼š{file_path}")
            return
        self.last_processed_file = file_path
        self._launch_auto_clean(file_path)


def get_log_monitor() -> LogMonitor:
    """å–å¾—å„²å­˜åœ¨ Streamlit session ä¸­çš„ LogMonitor å–®ä¾‹ã€‚"""
    if "cisco_log_monitor" not in st.session_state:
        st.session_state["cisco_log_monitor"] = LogMonitor()
    return st.session_state["cisco_log_monitor"]


def app() -> None:
    """Streamlit ç‰ˆçš„ Log æ“·å–é é¢ã€‚"""
    monitor = get_log_monitor()

    st.title("ğŸ“„ Cisco Log æ“·å–èˆ‡è‡ªå‹•åˆ†æ")
    st.markdown("æ­¤é é¢è² è²¬ç›£æ§ ASA logã€åŸ·è¡Œè³‡æ–™æ¸…æ´—èˆ‡è‡ªå‹•æ¨æ’­ã€‚")

    with st.form("log_settings"):
        save_dir = st.text_input("log å„²å­˜è³‡æ–™å¤¾", value=monitor.settings.get("save_dir", ""))
        binary_model = st.text_input("äºŒå…ƒæ¨¡å‹æª”æ¡ˆè·¯å¾‘", value=monitor.settings.get("binary_model_path", ""))
        multi_model = st.text_input("å¤šå…ƒæ¨¡å‹æª”æ¡ˆè·¯å¾‘", value=monitor.settings.get("model_path", ""))
        clean_dir = st.text_input("æ¸…æ´—è¼¸å‡ºè³‡æ–™å¤¾", value=monitor.settings.get("clean_csv_dir", ""))
        submitted = st.form_submit_button("ğŸ’¾ å„²å­˜è¨­å®š")
        if submitted:
            monitor.update_settings(
                save_dir=save_dir,
                binary_model_path=binary_model,
                model_path=multi_model,
                clean_csv_dir=clean_dir,
            )

    col1, col2, col3 = st.columns(3)
    if col1.button("â–¶ï¸ å•Ÿå‹•ç›£è½"):
        monitor.start_listening()
    if col2.button("â¹ï¸ åœæ­¢ç›£è½"):
        monitor.stop_listening()
    if col3.button("ğŸ” æ‰‹å‹•æƒæä¸€æ¬¡"):
        monitor.scan_once()

    manual_file = st.text_input("æ‰‹å‹•æŒ‡å®šè¦åˆ†æçš„ log æª”æ¡ˆè·¯å¾‘", value=monitor.last_processed_file)
    if st.button("âš™ï¸ ç«‹å³åŸ·è¡Œè‡ªå‹•åˆ†æ"):
        monitor.manual_auto_clean(manual_file)

    st.markdown("### ç›£æ§ç‹€æ…‹")
    status = "ğŸŸ¢ ç›£è½ä¸­" if monitor.listening else "â›” å·²åœæ­¢"
    st.write(f"ç›®å‰ç‹€æ…‹ï¼š{status}")
    if monitor.latest_result:
        st.success("é¡¯ç¤ºæœ€æ–°è‡ªå‹•åˆ†æçµæœï¼š")
        st.json(monitor.latest_result)

    st.markdown("### åŸ·è¡Œæ—¥èªŒ")
    st.text_area(
        "Log output",
        value="\n".join(monitor.log_messages),
        height=320,
    )
