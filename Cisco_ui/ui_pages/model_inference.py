"""Cisco æ¨¡å‹æ¨è«–é é¢æ¨¡çµ„ã€‚"""
from __future__ import annotations

import html
import os
import tempfile
from typing import Optional

import pandas as pd
import streamlit as st

from .log_monitor import get_log_monitor

# Import required modules with multiple fallback strategies
PipelineConfig = None
execute_pipeline = None
notification_pipeline = None
load_json = None

try:  # First try: package-relative imports when available
    from ..training_pipeline.config import PipelineConfig
    from ..training_pipeline.trainer import execute_pipeline
    from ..notifier import notification_pipeline
    from ..utils_labels import load_json
except (ImportError, ValueError):
    try:  # Second try: direct imports from package directory
        from training_pipeline.config import PipelineConfig  # type: ignore[no-redef]
        from training_pipeline.trainer import execute_pipeline  # type: ignore[no-redef]
        from notifier import notification_pipeline  # type: ignore[no-redef]
        from utils_labels import load_json  # type: ignore[no-redef]
    except ImportError:
        try:  # Third try: absolute imports from Cisco_ui
            from Cisco_ui.training_pipeline.config import PipelineConfig  # type: ignore[no-redef]
            from Cisco_ui.training_pipeline.trainer import execute_pipeline  # type: ignore[no-redef]
            from Cisco_ui.notifier import notification_pipeline  # type: ignore[no-redef]
            from Cisco_ui.utils_labels import load_json  # type: ignore[no-redef]
        except ImportError:
            # Final fallback: create stub functions to prevent crashes
            import warnings
            warnings.warn("Could not import Cisco pipeline modules. Some functionality will be limited.")
            
            class PipelineConfig:  # type: ignore[no-redef]
                def __init__(self, **kwargs):
                    pass
            
            def execute_pipeline(*args, **kwargs):  # type: ignore[no-redef]
                st.error("Pipeline execution not available - missing dependencies")
                return None
            
            def notification_pipeline(*args, **kwargs):  # type: ignore[no-redef]
                st.warning("Notification pipeline not available")
                return None
            
            def load_json(file_path, default=None):  # type: ignore[no-redef]
                import os
                if os.path.exists(file_path):
                    import json
                    with open(file_path, 'r', encoding='utf-8') as f:
                        return json.load(f)
                return default or {}

NOTIFIER_SETTINGS_FILE = "notifier_settings.txt"


def _write_temp_file(upload, suffix: str) -> Optional[str]:
    """å°‡ä¸Šå‚³æª”æ¡ˆå¯«å…¥æš«å­˜æª”ï¼Œå›å‚³å¯¦éš›è·¯å¾‘ã€‚"""
    if upload is None:
        return None
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(upload.getbuffer())
        return tmp.name


def _render_path_preview(label: str, value: str, *, icon: str = "ğŸ“") -> None:
    """ä»¥ä¸€è‡´æ¨£å¼å‘ˆç¾æª”æ¡ˆè·¯å¾‘æˆ–åç¨±ã€‚"""

    safe_label = html.escape(label)
    safe_icon = html.escape(icon)
    if value:
        safe_value = html.escape(value)
        extra_class = ""
    else:
        safe_value = "å°šæœªé¸æ“‡"
        extra_class = " path-preview--empty"

    # ä½¿ç”¨ inline flex è®“åœ–ç¤ºã€æ¨™ç±¤ã€è·¯å¾‘åœ¨åŒä¸€è¡Œé¡¯ç¤ºï¼Œé¿å… emoji æ›è¡Œ
    st.markdown(
        f"""
        <div class="path-preview{extra_class}" style="display:flex;align-items:center;gap:0.5rem;">
            <span class="path-preview__icon" style="flex:0 0 auto;font-size:1.1rem;">{safe_icon}</span>
            <span class="path-preview__text" style="white-space:nowrap;overflow:hidden;text-overflow:ellipsis;">
                <strong class="path-preview__label">{safe_label}</strong>&nbsp;
                <span class="path-preview__path">{safe_value}</span>
            </span>
        </div>
        """,
        unsafe_allow_html=True,
    )


def app() -> None:
    """æä¾›æ‰‹å‹•åŸ·è¡Œå®Œæ•´ Pipeline çš„é é¢ã€‚"""
    st.title("ğŸ” Cisco æ¨¡å‹æ¨è«–èˆ‡æ‰¹æ¬¡åˆ†æ")
    st.markdown("å¯æ‰‹å‹•é¸æ“‡åŸå§‹ log æª”èˆ‡æ¨¡å‹ï¼Œç«‹å³åŸ·è¡Œ Cisco ASA å…¨æµç¨‹åˆ†æã€‚")

    monitor = get_log_monitor()
    default_output = monitor.settings.get("clean_csv_dir", "")
    saved_log = monitor.last_processed_file
    saved_binary = st.session_state.get("cisco_binary_model_path", monitor.settings.get("binary_model_path", ""))
    saved_multi = st.session_state.get("cisco_multi_model_path", monitor.settings.get("model_path", ""))

    st.markdown("#### 1. é¸æ“‡è¼¸å…¥æª”æ¡ˆ")
    upload_log = st.file_uploader(
        "ä¸Šå‚³åŸå§‹ log (CSV/TXT/GZ)",
        type=["csv", "txt", "gz"],
        key="cisco_inference_log_uploader",
    )

    # æ±ºå®š checkbox çš„é è¨­å¯ç”¨æ€§ï¼ˆåœ¨ widget å»ºç«‹å‰è¨­å®š session_stateï¼‰
    can_use_recent = bool(saved_log) and (upload_log is None)
    # ç¢ºä¿ session_state åœ¨å»ºç«‹ widget å‰æœ‰é è¨­å€¼ï¼Œé¿å…å¾ŒçºŒç›´æ¥ä¿®æ”¹é€ æˆ Streamlit éŒ¯èª¤
    st.session_state.setdefault("cisco_use_recent_log_checkbox", can_use_recent)

    use_recent_log = st.checkbox(
        "ä½¿ç”¨æœ€è¿‘çš„ç›£æ§æª”æ¡ˆ",
        disabled=not can_use_recent,
        key="cisco_use_recent_log_checkbox",
        help="è‹¥å…ˆå‰æ–¼ã€ŒLog æ“·å–ã€é é¢å®Œæˆåˆ†æï¼Œå¯ç›´æ¥é‡ç”¨æœ€æ–°çš„æª”æ¡ˆã€‚",
    )

    # æ ¹æ“šä¸Šå‚³æˆ–é¸æ“‡é¡¯ç¤ºè·¯å¾‘é è¦½
    if upload_log is not None:
        # ç•¶ä½¿ç”¨è€…ä¸Šå‚³æ–°æª”æ¡ˆæ™‚ï¼Œè¦–ç‚ºä¸ä½¿ç”¨æœ€è¿‘æª”æ¡ˆ
        use_recent_log = False
        _render_path_preview("ä¸Šå‚³çš„ log æª”æ¡ˆ", upload_log.name, icon="ğŸ“„")
    elif use_recent_log and saved_log:
        _render_path_preview("æœ€è¿‘çš„ç›£æ§æª”æ¡ˆ", saved_log, icon="ğŸ“„")
    else:
        _render_path_preview("ç›®å‰é¸æ“‡çš„ log æª”æ¡ˆ", "", icon="ğŸ“„")
        if not saved_log:
            st.caption("å°šæœªæœ‰ç›£æ§ç´€éŒ„ï¼Œå¯æ–¼ã€ŒLog æ“·å–ã€é é¢åŸ·è¡Œè‡ªå‹•åˆ†æå¾Œå†å›åˆ°æ­¤è™•ã€‚")

    st.markdown("#### 2. æ¨¡å‹è¨­å®š")
    upload_binary = st.file_uploader(
        "ä¸Šå‚³äºŒå…ƒæ¨¡å‹ (.pkl/.joblib)",
        type=["pkl", "joblib"],
        key="binary_upload",
    )
    if upload_binary is not None:
        _render_path_preview("ä¸Šå‚³çš„äºŒå…ƒæ¨¡å‹", upload_binary.name, icon="ğŸ§ ")
    else:
        _render_path_preview("ç›®å‰å„²å­˜çš„äºŒå…ƒæ¨¡å‹", saved_binary, icon="ğŸ§ ")
        if not saved_binary:
            st.caption("å°šæœªè¨­å®šäºŒå…ƒæ¨¡å‹ï¼Œå¯æ–¼ã€ŒLog æ“·å–ã€é é¢ä¸Šå‚³ä¸¦å„²å­˜ã€‚")

    upload_multi = st.file_uploader(
        "ä¸Šå‚³å¤šå…ƒæ¨¡å‹ (.pkl/.joblib)",
        type=["pkl", "joblib"],
        key="multi_upload",
    )
    if upload_multi is not None:
        _render_path_preview("ä¸Šå‚³çš„å¤šå…ƒæ¨¡å‹", upload_multi.name, icon="ğŸ—‚ï¸")
    else:
        _render_path_preview("ç›®å‰å„²å­˜çš„å¤šå…ƒæ¨¡å‹", saved_multi, icon="ğŸ—‚ï¸")
        if not saved_multi:
            st.caption("å°šæœªè¨­å®šå¤šå…ƒæ¨¡å‹ï¼Œå¯æ–¼ã€ŒLog æ“·å–ã€é é¢ä¸Šå‚³ä¸¦å„²å­˜ã€‚")

    st.markdown("#### 3. è¼¸å‡ºè¨­å®š")
    output_dir = st.text_input(
        "è¼¸å‡ºè³‡æ–™å¤¾",
        value=default_output,
        placeholder="ä¾‹å¦‚ï¼š/data/cisco/output",
    )
    auto_notify = st.checkbox("è‡ªå‹•è§¸ç™¼é€šçŸ¥æ¨¡çµ„", value=True)

    if st.button("ğŸš€ åŸ·è¡Œ Pipeline"):
        log_path = None
        if upload_log is not None:
            log_suffix = os.path.splitext(upload_log.name)[1] or ".log"
            log_path = _write_temp_file(upload_log, suffix=log_suffix)
        elif use_recent_log and saved_log:
            log_path = saved_log

        binary_path = None
        if upload_binary is not None:
            binary_suffix = os.path.splitext(upload_binary.name)[1] or ".pkl"
            binary_path = _write_temp_file(upload_binary, suffix=binary_suffix)
        else:
            binary_path = saved_binary

        multi_path = None
        if upload_multi is not None:
            multi_suffix = os.path.splitext(upload_multi.name)[1] or ".pkl"
            multi_path = _write_temp_file(upload_multi, suffix=multi_suffix)
        else:
            multi_path = saved_multi

        errors = []
        if not log_path or not os.path.exists(log_path):
            errors.append("åŸå§‹ log")
        if not binary_path or not os.path.exists(binary_path):
            errors.append("äºŒå…ƒæ¨¡å‹")
        if not multi_path or not os.path.exists(multi_path):
            errors.append("å¤šå…ƒæ¨¡å‹")
        if not output_dir:
            errors.append("è¼¸å‡ºè³‡æ–™å¤¾")
        if errors:
            st.error("è«‹ç¢ºèªä»¥ä¸‹é …ç›®ï¼š" + "ã€".join(errors))
        else:
            os.makedirs(output_dir, exist_ok=True)
            try:
                config = PipelineConfig(
                    raw_log_path=log_path,
                    binary_model_path=binary_path,
                    multiclass_model_path=multi_path,
                    output_dir=output_dir,
                    show_progress=False,
                )
                # è¨ºæ–·æª”æ¡ˆæ˜¯å¦å­˜åœ¨
                st.write("æª”æ¡ˆæª¢æŸ¥:")
                st.write(f"- log_path: {log_path}, exists: {os.path.exists(log_path) if log_path else False}")
                st.write(f"- binary_path: {binary_path}, exists: {os.path.exists(binary_path) if binary_path else False}")
                st.write(f"- multi_path: {multi_path}, exists: {os.path.exists(multi_path) if multi_path else False}")
                
                # åŸ·è¡Œ pipelineï¼Œä½¿ç”¨é˜²è­·å¼éŒ¯èª¤è™•ç†ä»¥å–å¾—æ›´æ¸…æ¥šçš„éŒ¯èª¤è¨Šæ¯
                try:
                    result = execute_pipeline(config)
                    st.write("Pipeline result:", result)
                except Exception as pipe_exc:
                    st.error(f"Pipeline åŸ·è¡ŒéŒ¯èª¤: {pipe_exc}")
                    # å˜—è©¦å°‡åŸå§‹ exception traceback é¡¯ç¤ºçµ¦é–‹ç™¼è€…
                    import traceback
                    tb = traceback.format_exc()
                    st.text_area("Pipeline Traceback", tb, height=200)
                    result = None

                if result is None:
                    st.error("åˆ†ææœªç”¢ç”Ÿçµæœ (pipeline å›å‚³ None)ã€‚è«‹æª¢æŸ¥è¼¸å…¥æˆ– pipeline è¨­å®šã€‚")
                    # é¡¯ç¤º debug è¨Šæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                    if result and "debug" in result:
                        st.warning(f"[Debug] {result['debug']}")
                else:
                    st.success("åˆ†æå®Œæˆï¼")
                    try:
                        st.json(result)
                    except Exception:
                        st.write("åˆ†æçµæœï¼š", str(result))
                    st.session_state["cisco_manual_result"] = result
                    # é¡¯ç¤º debug è¨Šæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                    if result and "debug" in result:
                        st.info(f"[Debug] {result['debug']}")

                multi_csv = result.get("multiclass_output_csv") if result else None
                if multi_csv and os.path.exists(multi_csv):
                    st.markdown("#### å¤šå…ƒçµæœé è¦½")
                    try:
                        df_multi = pd.read_csv(multi_csv)
                        st.dataframe(df_multi.head(50))
                    except Exception as exc:  # pragma: no cover
                        st.warning(f"ç„¡æ³•è®€å–å¤šå…ƒçµæœï¼š{exc}")
                elif result is None:
                    st.warning("ç„¡æ³•é è¦½å¤šå…ƒçµæœï¼Œå› ç‚º pipeline åŸ·è¡Œå¤±æ•—æˆ–æœªç”¢ç”Ÿçµæœã€‚")

                if auto_notify:
                    st.info("è‡ªå‹•æ¨æ’­å•Ÿå‹•ä¸­...")
                    notifier_settings = load_json(NOTIFIER_SETTINGS_FILE, {})
                    fields = notifier_settings.get("convergence_fields", ["source", "destination"])
                    if not isinstance(fields, list):
                        fields = ["source", "destination"]
                    if result:
                        notification_pipeline(
                            result_csv=result.get("multiclass_output_csv", ""),
                            gemini_api_key=notifier_settings.get("gemini_api_key", ""),
                            line_channel_access_token=notifier_settings.get("line_channel_access_token", ""),
                            line_webhook_url=notifier_settings.get("line_webhook_url", ""),
                            discord_webhook_url=notifier_settings.get("discord_webhook_url", ""),
                            ui_callback=lambda msg: st.write(msg),
                            convergence_config={
                                "window_minutes": int(
                                    notifier_settings.get("convergence_window_minutes", 10) or 10
                                ),
                                "group_fields": fields,
                            },
                        )
                    else:
                        st.warning("è‡ªå‹•æ¨æ’­æœªå•Ÿå‹•ï¼Œå› ç‚º pipeline åŸ·è¡Œå¤±æ•—æˆ–æœªç”¢ç”Ÿçµæœã€‚")
            except Exception as exc:  # pragma: no cover
                st.error(f"åŸ·è¡Œå¤±æ•—ï¼š{exc}")

    if "cisco_manual_result" in st.session_state:
        st.markdown("### æœ€è¿‘ä¸€æ¬¡åˆ†æçµæœ")
        st.json(st.session_state["cisco_manual_result"])
