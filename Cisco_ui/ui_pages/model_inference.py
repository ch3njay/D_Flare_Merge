"""Cisco æ¨¡å‹æ¨è«–é é¢æ¨¡çµ„ã€‚"""
from __future__ import annotations

import html
import os
import tempfile
from typing import Optional

import pandas as pd
import streamlit as st

from .log_monitor import get_log_monitor

try:  # Package import when used via ``Cisco_ui``
    from ..training_pipeline.config import PipelineConfig
    from ..training_pipeline.trainer import execute_pipeline
    from ..notifier import notification_pipeline
    from ..utils_labels import load_json
except (ImportError, ValueError):  # Legacy support for running inside package folder
    from training_pipeline.config import PipelineConfig  # type: ignore[no-redef]
    from training_pipeline.trainer import execute_pipeline  # type: ignore[no-redef]
    from notifier import notification_pipeline  # type: ignore[no-redef]
    from utils_labels import load_json  # type: ignore[no-redef]

NOTIFIER_SETTINGS_FILE = "notifier_settings.txt"


def _write_temp_file(upload, suffix: str) -> Optional[str]:
    """å°‡ä¸Šå‚³æª”æ¡ˆå¯«å…¥æš«å­˜æª”ï¼Œå›å‚³å¯¦éš›è·¯å¾‘ã€‚"""
    if upload is None:
        return None
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(upload.getbuffer())
        return tmp.name


def _render_path_preview(label: str, value: str, *, icon: str = "ğŸ“") -> None:
    """ä»¥ä¸€è‡´æ¨£å¼å‘ˆç¾æª”æ¡ˆè·¯å¾‘æˆ–åç¨±ã€‚"""

    safe_label = html.escape(label)
    safe_icon = html.escape(icon)
    if value:
        safe_value = html.escape(value)
        extra_class = ""
    else:
        safe_value = "å°šæœªé¸æ“‡"
        extra_class = " path-preview--empty"

    st.markdown(
        f"""
        <div class="path-preview{extra_class}">
            <span class="path-preview__icon">{safe_icon}</span>
            <div class="path-preview__content">
                <span class="path-preview__label">{safe_label}</span>
                <span class="path-preview__path">{safe_value}</span>
            </div>
        </div>
        """,
        unsafe_allow_html=True,
    )


def app() -> None:
    """æä¾›æ‰‹å‹•åŸ·è¡Œå®Œæ•´ Pipeline çš„é é¢ã€‚"""
    st.title("ğŸ” Cisco æ¨¡å‹æ¨è«–èˆ‡æ‰¹æ¬¡åˆ†æ")
    st.markdown("å¯æ‰‹å‹•é¸æ“‡åŸå§‹ log æª”èˆ‡æ¨¡å‹ï¼Œç«‹å³åŸ·è¡Œ Cisco ASA å…¨æµç¨‹åˆ†æã€‚")

    monitor = get_log_monitor()
    default_output = monitor.settings.get("clean_csv_dir", "")
    saved_log = monitor.last_processed_file
    saved_binary = st.session_state.get("cisco_binary_model_path", monitor.settings.get("binary_model_path", ""))
    saved_multi = st.session_state.get("cisco_multi_model_path", monitor.settings.get("model_path", ""))

    st.markdown("#### 1. é¸æ“‡è¼¸å…¥æª”æ¡ˆ")
    upload_log = st.file_uploader(
        "ä¸Šå‚³åŸå§‹ log (CSV/TXT/GZ)",
        type=["csv", "txt", "gz"],
        key="cisco_inference_log_uploader",
    )
    can_use_recent = bool(saved_log)
    use_recent_log = st.checkbox(
        "ä½¿ç”¨æœ€è¿‘çš„ç›£æ§æª”æ¡ˆ",
        value=can_use_recent,
        disabled=not can_use_recent,
        key="cisco_use_recent_log_checkbox",
        help="è‹¥å…ˆå‰æ–¼ã€ŒLog æ“·å–ã€é é¢å®Œæˆåˆ†æï¼Œå¯ç›´æ¥é‡ç”¨æœ€æ–°çš„æª”æ¡ˆã€‚",
    )
    if not can_use_recent:
        use_recent_log = False
    if upload_log is not None:
        use_recent_log = False
        st.session_state["cisco_use_recent_log_checkbox"] = False
        _render_path_preview("ä¸Šå‚³çš„ log æª”æ¡ˆ", upload_log.name, icon="ğŸ“„")
    elif use_recent_log and saved_log:
        _render_path_preview("æœ€è¿‘çš„ç›£æ§æª”æ¡ˆ", saved_log, icon="ğŸ“„")
    else:
        _render_path_preview("ç›®å‰é¸æ“‡çš„ log æª”æ¡ˆ", "", icon="ğŸ“„")
        if not saved_log:
            st.caption("å°šæœªæœ‰ç›£æ§ç´€éŒ„ï¼Œå¯æ–¼ã€ŒLog æ“·å–ã€é é¢åŸ·è¡Œè‡ªå‹•åˆ†æå¾Œå†å›åˆ°æ­¤è™•ã€‚")

    st.markdown("#### 2. æ¨¡å‹è¨­å®š")
    upload_binary = st.file_uploader(
        "ä¸Šå‚³äºŒå…ƒæ¨¡å‹ (.pkl/.joblib)",
        type=["pkl", "joblib"],
        key="binary_upload",
    )
    if upload_binary is not None:
        _render_path_preview("ä¸Šå‚³çš„äºŒå…ƒæ¨¡å‹", upload_binary.name, icon="ğŸ§ ")
    else:
        _render_path_preview("ç›®å‰å„²å­˜çš„äºŒå…ƒæ¨¡å‹", saved_binary, icon="ğŸ§ ")
        if not saved_binary:
            st.caption("å°šæœªè¨­å®šäºŒå…ƒæ¨¡å‹ï¼Œå¯æ–¼ã€ŒLog æ“·å–ã€é é¢ä¸Šå‚³ä¸¦å„²å­˜ã€‚")

    upload_multi = st.file_uploader(
        "ä¸Šå‚³å¤šå…ƒæ¨¡å‹ (.pkl/.joblib)",
        type=["pkl", "joblib"],
        key="multi_upload",
    )
    if upload_multi is not None:
        _render_path_preview("ä¸Šå‚³çš„å¤šå…ƒæ¨¡å‹", upload_multi.name, icon="ğŸ—‚ï¸")
    else:
        _render_path_preview("ç›®å‰å„²å­˜çš„å¤šå…ƒæ¨¡å‹", saved_multi, icon="ğŸ—‚ï¸")
        if not saved_multi:
            st.caption("å°šæœªè¨­å®šå¤šå…ƒæ¨¡å‹ï¼Œå¯æ–¼ã€ŒLog æ“·å–ã€é é¢ä¸Šå‚³ä¸¦å„²å­˜ã€‚")

    st.markdown("#### 3. è¼¸å‡ºè¨­å®š")
    output_dir = st.text_input(
        "è¼¸å‡ºè³‡æ–™å¤¾",
        value=default_output,
        placeholder="ä¾‹å¦‚ï¼š/data/cisco/output",
    )
    auto_notify = st.checkbox("è‡ªå‹•è§¸ç™¼é€šçŸ¥æ¨¡çµ„", value=True)

    if st.button("ğŸš€ åŸ·è¡Œ Pipeline"):
        log_path = None
        if upload_log is not None:
            log_suffix = os.path.splitext(upload_log.name)[1] or ".log"
            log_path = _write_temp_file(upload_log, suffix=log_suffix)
        elif use_recent_log and saved_log:
            log_path = saved_log

        binary_path = None
        if upload_binary is not None:
            binary_suffix = os.path.splitext(upload_binary.name)[1] or ".pkl"
            binary_path = _write_temp_file(upload_binary, suffix=binary_suffix)
        else:
            binary_path = saved_binary

        multi_path = None
        if upload_multi is not None:
            multi_suffix = os.path.splitext(upload_multi.name)[1] or ".pkl"
            multi_path = _write_temp_file(upload_multi, suffix=multi_suffix)
        else:
            multi_path = saved_multi

        errors = []
        if not log_path or not os.path.exists(log_path):
            errors.append("åŸå§‹ log")
        if not binary_path or not os.path.exists(binary_path):
            errors.append("äºŒå…ƒæ¨¡å‹")
        if not multi_path or not os.path.exists(multi_path):
            errors.append("å¤šå…ƒæ¨¡å‹")
        if not output_dir:
            errors.append("è¼¸å‡ºè³‡æ–™å¤¾")
        if errors:
            st.error("è«‹ç¢ºèªä»¥ä¸‹é …ç›®ï¼š" + "ã€".join(errors))
        else:
            os.makedirs(output_dir, exist_ok=True)
            try:
                config = PipelineConfig(
                    raw_log_path=log_path,
                    binary_model_path=binary_path,
                    multiclass_model_path=multi_path,
                    output_dir=output_dir,
                    show_progress=False,
                )
                result = execute_pipeline(config)
                st.success("åˆ†æå®Œæˆï¼")
                st.json(result)
                st.session_state["cisco_manual_result"] = result

                multi_csv = result.get("multiclass_output_csv")
                if multi_csv and os.path.exists(multi_csv):
                    st.markdown("#### å¤šå…ƒçµæœé è¦½")
                    try:
                        df_multi = pd.read_csv(multi_csv)
                        st.dataframe(df_multi.head(50))
                    except Exception as exc:  # pragma: no cover
                        st.warning(f"ç„¡æ³•è®€å–å¤šå…ƒçµæœï¼š{exc}")

                if auto_notify:
                    st.info("è‡ªå‹•æ¨æ’­å•Ÿå‹•ä¸­...")
                    notifier_settings = load_json(NOTIFIER_SETTINGS_FILE, {})
                    fields = notifier_settings.get("convergence_fields", ["source", "destination"])
                    if not isinstance(fields, list):
                        fields = ["source", "destination"]
                    notification_pipeline(
                        result_csv=result.get("multiclass_output_csv", ""),
                        gemini_api_key=notifier_settings.get("gemini_api_key", ""),
                        line_channel_access_token=notifier_settings.get("line_channel_access_token", ""),
                        line_webhook_url=notifier_settings.get("line_webhook_url", ""),
                        discord_webhook_url=notifier_settings.get("discord_webhook_url", ""),
                        ui_callback=lambda msg: st.write(msg),
                        convergence_config={
                            "window_minutes": int(
                                notifier_settings.get("convergence_window_minutes", 10) or 10
                            ),
                            "group_fields": fields,
                        },
                    )
            except Exception as exc:  # pragma: no cover
                st.error(f"åŸ·è¡Œå¤±æ•—ï¼š{exc}")

    if "cisco_manual_result" in st.session_state:
        st.markdown("### æœ€è¿‘ä¸€æ¬¡åˆ†æçµæœ")
        st.json(st.session_state["cisco_manual_result"])
