import streamlit as st
import threading
import time
import os
import io
import contextlib
import queue
from . import _ensure_module, apply_dark_theme  # [MODIFIED]

_ensure_module("numpy", "numpy_stub")

_ensure_module("pandas", "pandas_stub")

import sys
from pathlib import Path

# ç¢ºä¿å°ˆæ¡ˆæ ¹ç›®éŒ„åœ¨ Python è·¯å¾‘ä¸­
_PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
if str(_PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(_PROJECT_ROOT))

_IMPORT_ERROR_MSG = ""
try:
    from Forti_ui_app_bundle.training_pipeline.pipeline_main import TrainingPipeline
    _TRAINING_PIPELINE_AVAILABLE = True
except ImportError as e1:
    _IMPORT_ERROR_MSG += f"Absolute import failed: {e1}\n"
    try:
        from ..training_pipeline.pipeline_main import TrainingPipeline
        _TRAINING_PIPELINE_AVAILABLE = True
    except ImportError as e2:
        _IMPORT_ERROR_MSG += f"Relative import failed: {e2}\n"
        # å˜—è©¦é€šéç›´æ¥æ·»åŠ è·¯å¾‘çš„æ–¹å¼
        try:
            import os
            forti_path = os.path.join(os.path.dirname(__file__), "..", "..")
            if forti_path not in sys.path:
                sys.path.insert(0, forti_path)
            from Forti_ui_app_bundle.training_pipeline.pipeline_main import TrainingPipeline
            _TRAINING_PIPELINE_AVAILABLE = True
        except ImportError as e3:
            _IMPORT_ERROR_MSG += f"Direct path import failed: {e3}\n"
            _TRAINING_PIPELINE_AVAILABLE = False
        # æä¾›ä¸€å€‹ç°¡å–®çš„ fallbackï¼Œä½†åœ¨ UI ä¸­æ˜ç¢ºå‘ŠçŸ¥ç”¨æˆ¶
        class TrainingPipeline:
            def __init__(self, *args, **kwargs):
                self.config = {}
                self.task_type = "binary"
                self.optuna_enabled = False
                self.optimize_base = False
                self.optimize_ensemble = False
                self.use_tuned_for_training = True
                
            def run(self, *args, **kwargs):
                raise ImportError("çœŸæ­£çš„ TrainingPipeline æ¨¡çµ„ç„¡æ³•è¼‰å…¥")


def app() -> None:
    apply_dark_theme()  # [ADDED]
    st.title("Training Pipeline")
    
    # æª¢æŸ¥ TrainingPipeline æ˜¯å¦å¯ç”¨
    if not _TRAINING_PIPELINE_AVAILABLE:
        st.error("âš ï¸ TrainingPipeline æ¨¡çµ„ç„¡æ³•è¼‰å…¥ï¼Œæ­¤åŠŸèƒ½æš«æ™‚ä¸å¯ç”¨ã€‚")
        with st.expander("è©³ç´°éŒ¯èª¤è¨Šæ¯"):
            st.code(_IMPORT_ERROR_MSG)
            st.code(f"Current working directory: {os.getcwd()}")
            st.code(f"Python path: {sys.path[:3]}...")
            st.code(f"File location: {__file__}")
        return
    
    st.markdown(
        """
        <style>
        .df-training-tip {
            background: color-mix(in srgb, var(--secondaryBackgroundColor) 80%, var(--backgroundColor) 20%);
            border: 1px solid color-mix(in srgb, var(--primaryColor) 28%, transparent);
            color: var(--textColor);
            padding: 0.85rem 1.1rem;
            border-radius: 0.85rem;
            margin-bottom: 1.2rem;
            box-shadow: 0 18px 36px -24px color-mix(in srgb, var(--primaryColor) 45%, transparent);
        }
        .df-training-tip strong {
            color: var(--primaryColor);
        }
        </style>
        <div class="df-training-tip">
            <strong>æç¤ºï¼š</strong>è¨“ç·´ç‹€æ…‹æœƒä¾ç…§ Streamlit ä¸»é¡Œè‡ªå‹•èª¿æ•´è‰²å½©ï¼Œç¢ºä¿åœ¨äº®/æš—æ¨¡å¼ä¸‹éƒ½å…·å‚™æ¸…æ™°å°æ¯”ã€‚
        </div>
        """,
        unsafe_allow_html=True,
    )

    # æª”æ¡ˆä¸Šå‚³
    st.subheader("1ï¸âƒ£ ä¸Šå‚³è¨“ç·´è³‡æ–™")
    uploaded_files = st.file_uploader(
        "é¸æ“‡è¨“ç·´è³‡æ–™æª”æ¡ˆ (æ”¯æ´å¤šæª”æ¡ˆé¸æ“‡)",
        type=["csv", "txt", "log", "gz", "zip"],
        accept_multiple_files=True,
        help="æ”¯æ´æ ¼å¼ï¼šCSV, TXT, LOG åŠå£“ç¸®æª” (.gz, .zip) | "
             "è«‹ä¸Šå‚³åŒ…å«ç‰¹å¾µå’Œæ¨™ç±¤ï¼ˆis_attack æˆ– crlevelï¼‰çš„è³‡æ–™æª”æ¡ˆ"
    )
    
    if uploaded_files:
        st.success(f"âœ… å·²é¸æ“‡ {len(uploaded_files)} å€‹æª”æ¡ˆ")
        with st.expander("ğŸ“ æŸ¥çœ‹é¸æ“‡çš„æª”æ¡ˆ"):
            for idx, file in enumerate(uploaded_files, 1):
                file_size = len(file.getvalue()) / 1024 / 1024  # MB
                st.text(f"{idx}. {file.name} ({file_size:.2f} MB)")
    
    # è¨“ç·´åƒæ•¸è¨­å®š
    st.subheader("2ï¸âƒ£ è¨“ç·´åƒæ•¸è¨­å®š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        task_type = st.selectbox(
            "ä»»å‹™é¡å‹",
            ["binary", "multiclass"],
            format_func=lambda x: "äºŒå…ƒåˆ†é¡ï¼ˆæ”»æ“Šåµæ¸¬ï¼‰" if x == "binary" else "å¤šå…ƒåˆ†é¡ï¼ˆé¢¨éšªç­‰ç´šï¼‰",
            help="é¸æ“‡è¨“ç·´ä»»å‹™é¡å‹"
        )
    
    with col2:
        test_size = st.slider(
            "æ¸¬è©¦é›†æ¯”ä¾‹",
            min_value=0.1,
            max_value=0.5,
            value=0.2,
            step=0.05,
            help="ç”¨æ–¼è©•ä¼°æ¨¡å‹çš„è³‡æ–™æ¯”ä¾‹"
        )
    
    # æ¨¡å‹é–¾å€¼è¨­å®š
    st.subheader("ğŸ¯ æ¨¡å‹é–¾å€¼èª¿æ•´")
    threshold = st.slider(
        "æ±ºç­–é–¾å€¼ (Decision Threshold)",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.01,
        help="èª¿æ•´æ¨¡å‹çš„æ±ºç­–é–¾å€¼ï¼Œå½±éŸ¿åˆ†é¡çš„æ•æ„Ÿåº¦èˆ‡ç‰¹ç•°æ€§"
    )

    # é€²éšè¨­å®š
    with st.expander("ğŸ”§ é€²éšè¨­å®š"):
        col1, col2 = st.columns(2)
        
        with col1:
            random_state = st.number_input(
                "éš¨æ©Ÿç¨®å­",
                min_value=0,
                value=42,
                help="è¨­å®šéš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿çµæœå¯é‡ç¾"
            )
            
            optuna_enabled = st.checkbox("Enable Optuna", value=False)
        
        with col2:
            output_dir = st.text_input(
                "è¼¸å‡ºç›®éŒ„",
                value="./artifacts",
                help="è¨“ç·´çµæœå’Œæ¨¡å‹çš„å„²å­˜ä½ç½®"
            )
        
        # Optuna è¨­å®š
        optimize_base = False
        optimize_ensemble = False
        use_tuned_for_training = False
        ensemble_mode = "free"

        if optuna_enabled:
            st.markdown("**Optuna å„ªåŒ–è¨­å®š**")
            col3, col4 = st.columns(2)
            
            with col3:
                optimize_base = st.checkbox("Optimize base models", value=False)
            
            with col4:
                optimize_ensemble = st.checkbox("Optimize ensemble", value=False)

            if optimize_base or optimize_ensemble:
                use_tuned_for_training = st.checkbox(
                    "Use tuned params for training", 
                    value=True
                )
                if optimize_ensemble and use_tuned_for_training:
                    ensemble_mode = st.selectbox(
                        "Ensemble mode",
                        ["free", "fixed"],
                        help="Optuna ensemble search mode",
                    )
            else:
                st.info("Optuna disabled because no optimization scope selected.")
                optuna_enabled = False

    # é–‹å§‹è¨“ç·´
    st.subheader("3ï¸âƒ£ é–‹å§‹è¨“ç·´")
    
    if not uploaded_files:
        st.warning("âš ï¸ è«‹å…ˆä¸Šå‚³è¨“ç·´è³‡æ–™")
        st.button("ğŸš€ é–‹å§‹è¨“ç·´", disabled=True)
        return
    
    # è™•ç†å¤šæª”æ¡ˆé¸æ“‡
    if len(uploaded_files) > 1:
        st.info(f"ï¿½ åµæ¸¬åˆ° {len(uploaded_files)} å€‹æª”æ¡ˆï¼Œå°‡ä½¿ç”¨ç¬¬ä¸€å€‹æª”æ¡ˆé€²è¡Œè¨“ç·´ï¼š**{uploaded_files[0].name}**")
    
    uploaded_file = uploaded_files[0]
    st.success(f"âœ… ä½¿ç”¨æª”æ¡ˆï¼š{uploaded_file.name}")

    if st.button("ğŸš€ é–‹å§‹è¨“ç·´", type="primary"):
        # å„²å­˜ä¸Šå‚³çš„æª”æ¡ˆåˆ°è‡¨æ™‚ç›®éŒ„
        tmp_path = f"uploaded_{uploaded_file.name}"
        with open(tmp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # å»ºç«‹è¨“ç·´ç®¡ç·šä¸¦è¨­å®šåƒæ•¸
        pipeline = TrainingPipeline(
            task_type=task_type,
            optuna_enabled=optuna_enabled,
            optimize_base=optimize_base,
            optimize_ensemble=optimize_ensemble,
            use_tuned_for_training=use_tuned_for_training,
        )
        
        # è¨­å®šæ¸¬è©¦é›†æ¯”ä¾‹å’Œé–¾å€¼
        if hasattr(pipeline, 'config') and pipeline.config:
            pipeline.config["VALID_SIZE"] = test_size
            pipeline.config["RANDOM_STATE"] = random_state
            pipeline.config.setdefault("ENSEMBLE_SETTINGS", {})["MODE"] = ensemble_mode
            pipeline.config.setdefault("ENSEMBLE_SETTINGS", {})["THRESHOLD"] = threshold
        progress = st.progress(0)
        status = st.empty()
        log_box = st.empty()

        result = {"error": None, "output": None}

        log_queue: "queue.Queue[str]" = queue.Queue()

        class _QueueStream(io.TextIOBase):
            def write(self, buf: str) -> int:
                log_queue.put(buf)
                return len(buf)

            def flush(self) -> None:
                pass

        def _run():
            try:
                stream = _QueueStream()
                with contextlib.redirect_stdout(stream), \
                     contextlib.redirect_stderr(stream):
                    result["output"] = pipeline.run(tmp_path)

            except Exception as exc:
                result["error"] = exc

        thread = threading.Thread(target=_run)
        thread.start()
        pct = 0
        log_text = ""
        while thread.is_alive():
            if pct < 95:
                pct += 5
            progress.progress(pct)
            status.text(f"Training in progress... {pct}%")
            while not log_queue.empty():
                log_text += log_queue.get()
            log_box.code(log_text)
            time.sleep(0.1)
        thread.join()
        while not log_queue.empty():
            log_text += log_queue.get()
        log_box.code(log_text)
        if result["error"] is None:
            progress.progress(100)
            status.text("Training finished")
            st.success("Training finished")

            # Debug: æª¢æŸ¥ result çµæ§‹
            st.write(f"DEBUG: result keys: {list(result.keys())}")
            st.write(f"DEBUG: result['error']: {result.get('error')}")
            st.write(f"DEBUG: result['output'] type: {type(result.get('output'))}")
            if result.get("output"):
                st.write(f"DEBUG: output keys: {list(result['output'].keys())}")
            
            artifacts_dir = result["output"].get("artifacts_dir") if result["output"] else None
            if artifacts_dir:

                from pathlib import Path
                import os

                st.write(f"DEBUG: artifacts_dir = {artifacts_dir}")
                
                # æª¢æŸ¥ç›®éŒ„æ˜¯å¦å­˜åœ¨
                if os.path.exists(artifacts_dir):
                    st.write(f"DEBUG: artifacts_dir exists")
                    # åˆ—å‡ºç›®éŒ„å…§å®¹
                    try:
                        contents = os.listdir(artifacts_dir)
                        st.write(f"DEBUG: artifacts_dir contents: {contents}")
                        
                        models_dir = os.path.join(artifacts_dir, "models")
                        if os.path.exists(models_dir):
                            models_contents = os.listdir(models_dir)
                            st.write(f"DEBUG: models dir contents: {models_contents}")
                        else:
                            st.write("DEBUG: models directory does not exist")
                    except Exception as e:
                        st.write(f"DEBUG: Error listing contents: {e}")
                else:
                    st.write(f"DEBUG: artifacts_dir does not exist")

                model_path = Path(artifacts_dir) / "models" / "ensemble_best.joblib"
                st.write(f"DEBUG: Looking for model at: {model_path}")
                if model_path.exists():

                    with open(model_path, "rb") as f:
                        model_bytes = f.read()
                    st.download_button(
                        "Download ensemble model",
                        model_bytes,
                        file_name="ensemble_best.joblib",
                    )
                    st.info(f"Artifacts saved to: {artifacts_dir}")
                else:
                    st.warning("Model file not found in artifacts directory.")

            else:
                st.warning("No artifacts directory returned.")


        else:
            status.text("Training failed")
            error_msg = result['error']
            st.error(f"Training failed: {error_msg}")
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯ CSV æ ¼å¼éŒ¯èª¤
            if ("Error tokenizing data" in str(error_msg) or 
                ("Expected" in str(error_msg) and "fields" in str(error_msg))):
                st.markdown("---")
                st.subheader("ğŸ” CSV æ ¼å¼è¨ºæ–·")
                st.warning(
                    "æª¢æ¸¬åˆ° CSV æ ¼å¼å•é¡Œã€‚é€™é€šå¸¸æ˜¯ç”±æ–¼ï¼š\n"
                    "- æŸäº›è¡Œçš„æ¬„ä½æ•¸é‡ä¸ä¸€è‡´\n"
                    "- æ•¸æ“šä¸­åŒ…å«æœªè½‰ç¾©çš„åˆ†éš”ç¬¦ï¼ˆå¦‚é€—è™Ÿï¼‰\n"
                    "- å¼•è™Ÿæ ¼å¼ä¸æ­£ç¢º"
                )
                
                with st.expander("ğŸ› ï¸ å»ºè­°çš„è§£æ±ºæ–¹æ¡ˆ"):
                    st.markdown("""
                    **1. æª¢æŸ¥æ–‡ä»¶æ ¼å¼**
                    - ä½¿ç”¨æ–‡æœ¬ç·¨è¼¯å™¨æ‰“é–‹ CSV æ–‡ä»¶
                    - æª¢æŸ¥éŒ¯èª¤æåˆ°çš„è¡Œæ•¸ï¼ˆå¦‚ç¬¬22è¡Œï¼‰
                    - ç¢ºèªæ¯è¡Œçš„æ¬„ä½æ•¸é‡æ˜¯å¦ä¸€è‡´
                    
                    **2. ä¿®å¾©å¸¸è¦‹å•é¡Œ**
                    - å¦‚æœæ–‡æœ¬æ¬„ä½åŒ…å«é€—è™Ÿï¼Œè«‹ç”¨é›™å¼•è™ŸåŒ…åœ
                    - å¦‚æœæœ‰æ›è¡Œç¬¦åœ¨æ–‡æœ¬ä¸­ï¼Œè«‹ç§»é™¤æˆ–æ›¿æ›
                    - ç¢ºä¿æ‰€æœ‰è¡Œçš„æ¬„ä½æ•¸é‡ç›¸åŒ
                    
                    **3. ä½¿ç”¨å·¥å…·ä¿®å¾©**
                    - å¯ä»¥ä½¿ç”¨ Excel æ‰“é–‹ä¸¦é‡æ–°ä¿å­˜ç‚º CSV æ ¼å¼
                    - æˆ–ä½¿ç”¨å°ˆé–€çš„ CSV æ¸…ç†å·¥å…·
                    
                    **4. æ¸¬è©¦å»ºè­°**
                    - å…ˆç”¨è¼ƒå°çš„æ•¸æ“šé›†ï¼ˆå¦‚å‰100è¡Œï¼‰é€²è¡Œæ¸¬è©¦
                    - ç¢ºèªæ ¼å¼æ­£ç¢ºå¾Œå†ä½¿ç”¨å®Œæ•´æ•¸æ“šé›†
                    """)
    
    # ä½¿ç”¨èªªæ˜
    with st.expander("â„¹ï¸ ä½¿ç”¨èªªæ˜"):
        st.markdown("""
        ### è³‡æ–™æ ¼å¼è¦æ±‚
        
        #### äºŒå…ƒåˆ†é¡ (binary)
        - å¿…é ˆåŒ…å« `is_attack` æ¬„ä½ï¼ˆ0: æ­£å¸¸, 1: æ”»æ“Šï¼‰
        - å…¶ä»–æ¬„ä½ä½œç‚ºç‰¹å¾µ
        
        #### å¤šå…ƒåˆ†é¡ (multiclass)
        - å¿…é ˆåŒ…å« `crlevel` æ¬„ä½ï¼ˆ0-4: é¢¨éšªç­‰ç´šï¼‰
        - å…¶ä»–æ¬„ä½ä½œç‚ºç‰¹å¾µ
        
        ### åƒæ•¸èªªæ˜
        
        #### æ¸¬è©¦é›†æ¯”ä¾‹
        - æ§åˆ¶ç”¨æ–¼è©•ä¼°æ¨¡å‹æ•ˆèƒ½çš„è³‡æ–™æ¯”ä¾‹
        - å»ºè­°å€¼ï¼š0.2 (20%) åˆ° 0.3 (30%)
        
        #### æ±ºç­–é–¾å€¼ (Threshold)
        - **0.5**: å¹³è¡¡æ•æ„Ÿåº¦å’Œç‰¹ç•°æ€§ï¼ˆé è¨­å€¼ï¼‰
        - **< 0.5**: æé«˜æ•æ„Ÿåº¦ï¼Œæ¸›å°‘æ¼å ±ï¼ˆFalse Negativeï¼‰
        - **> 0.5**: æé«˜ç‰¹ç•°æ€§ï¼Œæ¸›å°‘èª¤å ±ï¼ˆFalse Positiveï¼‰
        - æ”»æ“Šåµæ¸¬å»ºè­°ï¼š0.3-0.4ï¼ˆå„ªå…ˆé¿å…æ¼å ±ï¼‰
        
        #### Optuna å„ªåŒ–
        - **Optimize base models**: è‡ªå‹•èª¿æ•´å–®ä¸€æ¨¡å‹åƒæ•¸
        - **Optimize ensemble**: è‡ªå‹•èª¿æ•´é›†æˆç­–ç•¥
        - **Free mode**: éˆæ´»çš„é›†æˆæœå°‹
        - **Fixed mode**: å›ºå®šçš„é›†æˆçµæ§‹
        
        ### è¨“ç·´æµç¨‹
        1. **è³‡æ–™è¼‰å…¥**ï¼šè®€å–ä¸¦åˆä½µå¤šå€‹æª”æ¡ˆ
        2. **ç‰¹å¾µæº–å‚™**ï¼šè‡ªå‹•ç‰¹å¾µé¸æ“‡å’Œå·¥ç¨‹
        3. **è³‡æ–™åˆ†å‰²**ï¼šæŒ‰æŒ‡å®šæ¯”ä¾‹åˆ†ç‚ºè¨“ç·´é›†å’Œæ¸¬è©¦é›†
        4. **æ¨¡å‹è¨“ç·´**ï¼šè¨“ç·´ XGBã€LGBã€CATã€RFã€ET æ¨¡å‹
        5. **é›†æˆå„ªåŒ–**ï¼šä½¿ç”¨ Stacking æˆ– Voting æ–¹æ³•
        6. **é–¾å€¼æ‡‰ç”¨**ï¼šæ ¹æ“šè¨­å®šçš„é–¾å€¼é€²è¡Œæœ€çµ‚é æ¸¬
        7. **çµæœå„²å­˜**ï¼šå„²å­˜æ¨¡å‹å’Œè©•ä¼°å ±å‘Š
        
        ### è¼¸å‡ºæª”æ¡ˆ
        - `models/`: è¨“ç·´å¥½çš„æ¨¡å‹æª”æ¡ˆ (.joblib)
        - `reports/`: è©³ç´°çš„è©•ä¼°å ±å‘Šå’ŒæŒ‡æ¨™
        - `ensemble_best.joblib`: æœ€ä½³é›†æˆæ¨¡å‹
        
        ### æ³¨æ„äº‹é …
        - ç¢ºä¿è³‡æ–™é›†å¤§å°è¶³å¤ ï¼ˆå»ºè­° > 10,000 ç­†ï¼‰
        - é¡åˆ¥åˆ†ä½ˆä¸è¦éæ–¼ä¸å¹³è¡¡
        - è¨“ç·´æ™‚é–“ä¾è³‡æ–™é‡å’Œ Optuna è¨­å®šè€Œå®š
        - é–¾å€¼èª¿æ•´æœƒå½±éŸ¿æœ€çµ‚çš„åˆ†é¡æ•ˆæœ
        """)
