#!/usr/bin/env python3
"""æ›´åš´è¬¹çš„æ·±åº¦æª¢æŸ¥å·¥å…· - å…¨é¢é©—è­‰é›†æˆåŠŸèƒ½çš„ç©©å®šæ€§å’Œå¯é æ€§"""

import sys
import os
import ast
import tempfile
import traceback
import warnings
import time
import gc
import threading
import multiprocessing
import psutil
from typing import Dict, Any, List, Tuple, Optional
import numpy as np
import pandas as pd
from sklearn.datasets import make_classification, make_multilabel_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

class RigorousTestSuite:
    """æ›´åš´è¬¹çš„æ¸¬è©¦å¥—ä»¶"""
    
    def __init__(self):
        self.test_results = []
        self.errors = []
        self.warnings = []
        self.critical_failures = []
        
    def log_test(self, test_name: str, success: bool, message: str = "", 
                 severity: str = "info", details: Dict = None):
        """è¨˜éŒ„æ¸¬è©¦çµæœ"""
        result = {
            "test_name": test_name,
            "success": success,
            "message": message,
            "severity": severity,
            "details": details or {},
            "timestamp": time.time()
        }
        self.test_results.append(result)
        
        # æ ¹æ“šåš´é‡ç¨‹åº¦é¸æ“‡åœ–æ¨™
        if severity == "critical":
            status = "ğŸ”¥"
            self.critical_failures.append(result)
        elif severity == "error":
            status = "âŒ"
            self.errors.append(result)
        elif severity == "warning":
            status = "âš ï¸"
            self.warnings.append(result)
        else:
            status = "âœ…" if success else "âŒ"
        
        print(f"{status} {test_name}: {message}")
        
    def deep_syntax_check(self):
        """æ·±åº¦èªæ³•æª¢æŸ¥"""
        print("\nğŸ” æ·±åº¦èªæ³•å’Œé‹è¡Œæ™‚æª¢æŸ¥...")
        
        files_to_check = [
            "d:\\work\\PROJECT\\D_Flare_Merge\\Forti_ui_app_bundle\\training_pipeline\\combo_optimizer.py",
            "d:\\work\\PROJECT\\D_Flare_Merge\\Cisco_ui\\training_pipeline\\combo_optimizer.py",
            "d:\\work\\PROJECT\\D_Flare_Merge\\Cisco_ui\\training_pipeline\\pipeline_main.py",
            "d:\\work\\PROJECT\\D_Flare_Merge\\Cisco_ui\\training_pipeline\\ensemble_optuna.py",
            "d:\\work\\PROJECT\\D_Flare_Merge\\Forti_ui_app_bundle\\training_pipeline\\ensemble_optuna.py"
        ]
        
        for file_path in files_to_check:
            if os.path.exists(file_path):
                self._check_file_syntax(file_path)
            else:
                self.log_test(f"file_exists_{os.path.basename(file_path)}", 
                             False, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}", "error")
    
    def _check_file_syntax(self, file_path: str):
        """æª¢æŸ¥å–®å€‹æ–‡ä»¶çš„èªæ³•"""
        try:
            file_name = os.path.basename(file_path)
            
            # 1. è®€å–æ–‡ä»¶å…§å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # 2. AST èªæ³•æª¢æŸ¥
            try:
                ast.parse(content)
                self.log_test(f"ast_parse_{file_name}", True, "AST èªæ³•è§£ææˆåŠŸ")
            except SyntaxError as e:
                self.log_test(f"ast_parse_{file_name}", False, 
                             f"èªæ³•éŒ¯èª¤: {e}", "critical")
                return
            
            # 3. ç·¨è­¯æª¢æŸ¥
            try:
                compile(content, file_path, 'exec')
                self.log_test(f"compile_{file_name}", True, "ç·¨è­¯æª¢æŸ¥é€šé")
            except Exception as e:
                self.log_test(f"compile_{file_name}", False, 
                             f"ç·¨è­¯éŒ¯èª¤: {e}", "error")
            
            # 4. å°å…¥æª¢æŸ¥
            if file_name == "combo_optimizer.py":
                self._test_module_import(file_path)
            
            # 5. é¡å‹ä¸€è‡´æ€§æª¢æŸ¥
            self._check_type_consistency(file_path, content)
            
        except Exception as e:
            self.log_test(f"syntax_check_{os.path.basename(file_path)}", 
                         False, f"æª¢æŸ¥å¤±æ•—: {e}", "critical")
    
    def _test_module_import(self, file_path: str):
        """æ¸¬è©¦æ¨¡çµ„å°å…¥"""
        try:
            if "Forti_ui_app_bundle" in file_path:
                from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
                self.log_test("import_fortinet_combo", True, "Fortinet ComboOptimizer å°å…¥æˆåŠŸ")
            elif "Cisco_ui" in file_path:
                from Cisco_ui.training_pipeline.combo_optimizer import ComboOptimizer
                self.log_test("import_cisco_combo", True, "Cisco ComboOptimizer å°å…¥æˆåŠŸ")
        except ImportError as e:
            self.log_test("import_module", False, f"æ¨¡çµ„å°å…¥å¤±æ•—: {e}", "error")
        except Exception as e:
            self.log_test("import_module", False, f"å°å…¥æ¸¬è©¦ç•°å¸¸: {e}", "warning")
    
    def _check_type_consistency(self, file_path: str, content: str):
        """æª¢æŸ¥é¡å‹ä¸€è‡´æ€§"""
        file_name = os.path.basename(file_path)
        
        # æª¢æŸ¥å¸¸è¦‹çš„é¡å‹ä¸ä¸€è‡´å•é¡Œ
        issues = []
        
        # æª¢æŸ¥ X_train/x_train ä¸€è‡´æ€§
        if 'X_train' in content and 'x_train' in content:
            issues.append("è®Šæ•¸å‘½åä¸ä¸€è‡´: X_train å’Œ x_train åŒæ™‚å­˜åœ¨")
        
        # æª¢æŸ¥è¿”å›é¡å‹è¨»è§£
        import re
        func_defs = re.findall(r'def\s+\w+\([^)]*\)\s*->\s*([^:]+):', content)
        for return_type in func_defs:
            if 'Dict[str, Dict]' in return_type:
                issues.append("è¿”å›é¡å‹è¨»è§£ä¸å®Œæ•´: Dict[str, Dict] æ‡‰è©²æ˜¯ Dict[str, Dict[str, Any]]")
        
        if issues:
            self.log_test(f"type_consistency_{file_name}", False, 
                         f"é¡å‹ä¸€è‡´æ€§å•é¡Œ: {'; '.join(issues)}", "warning")
        else:
            self.log_test(f"type_consistency_{file_name}", True, "é¡å‹ä¸€è‡´æ€§æª¢æŸ¥é€šé")

    def strict_dependency_verification(self):
        """åš´æ ¼ä¾è³´é—œä¿‚é©—è­‰"""
        print("\nğŸ”— åš´æ ¼ä¾è³´é—œä¿‚é©—è­‰...")
        
        # 1. æª¢æŸ¥ Python ç‰ˆæœ¬å…¼å®¹æ€§
        self._check_python_version()
        
        # 2. æª¢æŸ¥å¿…è¦ä¾è³´
        self._check_required_dependencies()
        
        # 3. æª¢æŸ¥å¾ªç’°å°å…¥
        self._check_circular_imports()
        
        # 4. æª¢æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§
        self._check_version_compatibility()
    
    def _check_python_version(self):
        """æª¢æŸ¥ Python ç‰ˆæœ¬"""
        current_version = sys.version_info
        min_version = (3, 8)
        
        if current_version >= min_version:
            self.log_test("python_version", True, 
                         f"Python ç‰ˆæœ¬ {current_version.major}.{current_version.minor} å…¼å®¹")
        else:
            self.log_test("python_version", False, 
                         f"Python ç‰ˆæœ¬éä½: {current_version.major}.{current_version.minor} < 3.8", 
                         "critical")
    
    def _check_required_dependencies(self):
        """æª¢æŸ¥å¿…è¦ä¾è³´"""
        required_packages = [
            ('numpy', 'np'),
            ('pandas', 'pd'),
            ('sklearn', 'sklearn'),
            ('joblib', 'joblib'),
            ('optuna', 'optuna')
        ]
        
        for package, alias in required_packages:
            try:
                __import__(package)
                self.log_test(f"dependency_{package}", True, f"ä¾è³´ {package} å¯ç”¨")
            except ImportError:
                self.log_test(f"dependency_{package}", False, 
                             f"ç¼ºå°‘å¿…è¦ä¾è³´: {package}", "error")
    
    def _check_circular_imports(self):
        """æª¢æŸ¥å¾ªç’°å°å…¥"""
        try:
            # æ¸¬è©¦å¯èƒ½çš„å¾ªç’°å°å…¥è·¯å¾‘
            import importlib
            import sys
            
            # æ¸…é™¤æ¨¡çµ„ç·©å­˜
            modules_to_clear = [m for m in sys.modules.keys() 
                              if 'combo_optimizer' in m or 'ensemble_optuna' in m]
            for mod in modules_to_clear:
                if mod in sys.modules:
                    del sys.modules[mod]
            
            # å˜—è©¦å°å…¥
            from Forti_ui_app_bundle.training_pipeline import combo_optimizer
            from Cisco_ui.training_pipeline import combo_optimizer as cisco_combo
            
            self.log_test("circular_imports", True, "ç„¡å¾ªç’°å°å…¥å•é¡Œ")
            
        except ImportError as e:
            if "circular import" in str(e).lower():
                self.log_test("circular_imports", False, f"ç™¼ç¾å¾ªç’°å°å…¥: {e}", "error")
            else:
                self.log_test("circular_imports", True, "ç„¡å¾ªç’°å°å…¥å•é¡Œ")
        except Exception as e:
            self.log_test("circular_imports", False, f"å°å…¥æª¢æŸ¥ç•°å¸¸: {e}", "warning")
    
    def _check_version_compatibility(self):
        """æª¢æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§"""
        try:
            import sklearn
            import numpy as np
            import pandas as pd
            
            # æª¢æŸ¥ sklearn ç‰ˆæœ¬
            sklearn_version = sklearn.__version__
            if sklearn_version >= "1.0.0":
                self.log_test("sklearn_version", True, f"sklearn {sklearn_version} å…¼å®¹")
            else:
                self.log_test("sklearn_version", False, 
                             f"sklearn ç‰ˆæœ¬éä½: {sklearn_version}", "warning")
            
            # æª¢æŸ¥ numpy ç‰ˆæœ¬
            numpy_version = np.__version__
            if numpy_version >= "1.19.0":
                self.log_test("numpy_version", True, f"numpy {numpy_version} å…¼å®¹")
            else:
                self.log_test("numpy_version", False, 
                             f"numpy ç‰ˆæœ¬éä½: {numpy_version}", "warning")
            
        except Exception as e:
            self.log_test("version_compatibility", False, f"ç‰ˆæœ¬æª¢æŸ¥å¤±æ•—: {e}", "error")

    def extreme_edge_case_testing(self):
        """æ¥µé™é‚Šç•Œæƒ…æ³æ¸¬è©¦"""
        print("\nâš¡ æ¥µé™é‚Šç•Œæƒ…æ³æ¸¬è©¦...")
        
        # 1. å·¨å¤§æ•¸æ“šé›†æ¸¬è©¦
        self._test_massive_dataset()
        
        # 2. æå£æ•¸æ“šæ¸¬è©¦
        self._test_corrupted_data()
        
        # 3. ä½µç™¼è¨ªå•æ¸¬è©¦
        self._test_concurrent_access()
        
        # 4. è³‡æºè€—ç›¡æ¸¬è©¦
        self._test_resource_exhaustion()
    
    def _test_massive_dataset(self):
        """æ¸¬è©¦å·¨å¤§æ•¸æ“šé›†"""
        try:
            print("  ğŸ”„ æ¸¬è©¦å¤§å‹æ•¸æ“šé›†è™•ç†...")
            
            # å‰µå»ºå¤§å‹æ•¸æ“šé›† (50k æ¨£æœ¬)
            X, y = make_classification(
                n_samples=50000,
                n_features=100,
                n_informative=80,
                n_classes=2,
                random_state=42
            )
            
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.1, random_state=42  # åªç”¨ 10% ä½œç‚ºæ¸¬è©¦é›†ç¯€çœæ™‚é–“
            )
            
            # ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
            
            models = [
                ('rf', RandomForestClassifier(n_estimators=5, random_state=42, n_jobs=1)),
                ('lr', LogisticRegression(random_state=42, max_iter=50))  # æ¸›å°‘è¿­ä»£æ¬¡æ•¸
            ]
            
            for name, model in models:
                model.fit(X_train, y_train)
            
            with tempfile.TemporaryDirectory() as temp_dir:
                start_time = time.time()
                
                combo_opt = ComboOptimizer(
                    estimators=models,
                    X_train=X_train,
                    y_train=y_train,
                    X_valid=X_test,
                    y_valid=y_test,
                    task_type="binary",
                    config={"ENSEMBLE_SETTINGS": {"VOTING": "soft"}},
                    out_dir=temp_dir
                )
                
                result = combo_opt.optimize()
                
                end_time = time.time()
                final_memory = process.memory_info().rss / 1024 / 1024  # MB
                
                duration = end_time - start_time
                memory_increase = final_memory - initial_memory
                
                # æª¢æŸ¥çµæœ
                if result and 'metrics' in result:
                    # æ€§èƒ½æ¨™æº–ï¼š50k æ¨£æœ¬ä¸è¶…é 5 åˆ†é˜
                    time_ok = duration < 300
                    # è¨˜æ†¶é«”æ¨™æº–ï¼šå¢é•·ä¸è¶…é 2GB
                    memory_ok = memory_increase < 2000
                    
                    if time_ok and memory_ok:
                        self.log_test("massive_dataset", True, 
                                     f"å¤§å‹æ•¸æ“šé›†è™•ç†æˆåŠŸ: {duration:.1f}s, +{memory_increase:.1f}MB")
                    else:
                        self.log_test("massive_dataset", False, 
                                     f"æ€§èƒ½ä¸é”æ¨™: {duration:.1f}s, +{memory_increase:.1f}MB", 
                                     "warning")
                else:
                    self.log_test("massive_dataset", False, "å¤§å‹æ•¸æ“šé›†è™•ç†å¤±æ•—", "error")
                    
        except MemoryError:
            self.log_test("massive_dataset", False, "è¨˜æ†¶é«”ä¸è¶³", "error")
        except Exception as e:
            self.log_test("massive_dataset", False, f"å¤§å‹æ•¸æ“šé›†æ¸¬è©¦å¤±æ•—: {e}", "error")
    
    def _test_corrupted_data(self):
        """æ¸¬è©¦æå£æ•¸æ“š"""
        print("  ğŸ› ï¸ æ¸¬è©¦æå£æ•¸æ“šè™•ç†...")
        
        try:
            from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
            
            # å‰µå»ºæ­£å¸¸æ•¸æ“š
            X, y = make_classification(n_samples=100, n_features=10, n_classes=2, random_state=42)
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            # æ¸¬è©¦å„ç¨®æå£çš„æ•¸æ“š
            corruption_tests = [
                ("nan_features", self._create_nan_data(X_train), y_train, X_test, y_test),
                ("inf_features", self._create_inf_data(X_train), y_train, X_test, y_test),
                ("mismatched_dimensions", X_train[:50], y_train, X_test, y_test),
                ("wrong_label_type", X_train, y_train.astype(str), X_test, y_test),
            ]
            
            for test_name, X_corrupt, y_corrupt, X_val, y_val in corruption_tests:
                try:
                    models = [('rf', RandomForestClassifier(n_estimators=3, random_state=42))]
                    
                    # å˜—è©¦è¨“ç·´æ¨¡å‹
                    for name, model in models:
                        model.fit(X_corrupt, y_corrupt)
                    
                    with tempfile.TemporaryDirectory() as temp_dir:
                        combo_opt = ComboOptimizer(
                            estimators=models,
                            X_train=X_corrupt,
                            y_train=y_corrupt,
                            X_valid=X_val,
                            y_valid=y_val,
                            task_type="binary",
                            config={},
                            out_dir=temp_dir
                        )
                        
                        result = combo_opt.optimize()
                        
                        # æŸäº›æå£æ•¸æ“šæ‡‰è©²è¢«è™•ç†æˆ–æ‹’çµ•
                        if test_name in ["nan_features", "inf_features", "wrong_label_type"]:
                            self.log_test(f"corrupted_data_{test_name}", True, 
                                         "æå£æ•¸æ“šè¢«å¦¥å–„è™•ç†æˆ–æ‹’çµ•")
                        else:
                            self.log_test(f"corrupted_data_{test_name}", True, 
                                         "æå£æ•¸æ“šè™•ç†æ­£å¸¸")
                
                except Exception as e:
                    # å°æ–¼æŸäº›æå£æ•¸æ“šï¼Œæ‹‹å‡ºç•°å¸¸æ˜¯é æœŸçš„
                    if test_name in ["mismatched_dimensions", "wrong_label_type"]:
                        self.log_test(f"corrupted_data_{test_name}", True, 
                                     f"æ­£ç¢ºæ‹’çµ•æå£æ•¸æ“š: {type(e).__name__}")
                    else:
                        self.log_test(f"corrupted_data_{test_name}", False, 
                                     f"æå£æ•¸æ“šè™•ç†å¤±æ•—: {e}", "warning")
                
        except Exception as e:
            self.log_test("corrupted_data", False, f"æå£æ•¸æ“šæ¸¬è©¦å¤±æ•—: {e}", "error")
    
    def _create_nan_data(self, X):
        """å‰µå»ºåŒ…å« NaN çš„æ•¸æ“š"""
        X_nan = X.copy()
        X_nan[0, 0] = np.nan
        X_nan[1, 1] = np.nan
        return X_nan
    
    def _create_inf_data(self, X):
        """å‰µå»ºåŒ…å« Inf çš„æ•¸æ“š"""
        X_inf = X.copy()
        X_inf[0, 0] = np.inf
        X_inf[1, 1] = -np.inf
        return X_inf
    
    def _test_concurrent_access(self):
        """æ¸¬è©¦ä½µç™¼è¨ªå•"""
        print("  ğŸ”„ æ¸¬è©¦ä½µç™¼è¨ªå•...")
        
        def worker_function(worker_id):
            """å·¥ä½œç·šç¨‹å‡½æ•¸"""
            try:
                from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
                
                X, y = make_classification(n_samples=50, n_features=5, n_classes=2, random_state=worker_id)
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=worker_id)
                
                models = [('rf', RandomForestClassifier(n_estimators=2, random_state=worker_id))]
                for name, model in models:
                    model.fit(X_train, y_train)
                
                with tempfile.TemporaryDirectory() as temp_dir:
                    combo_opt = ComboOptimizer(
                        estimators=models,
                        X_train=X_train,
                        y_train=y_train,
                        X_valid=X_test,
                        y_valid=y_test,
                        task_type="binary",
                        config={},
                        out_dir=temp_dir
                    )
                    
                    result = combo_opt.optimize()
                    return result is not None and 'metrics' in result
                    
            except Exception as e:
                print(f"Worker {worker_id} å¤±æ•—: {e}")
                return False
        
        try:
            # å‰µå»ºå¤šå€‹ç·šç¨‹åŒæ™‚åŸ·è¡Œ
            threads = []
            results = []
            
            def thread_wrapper(worker_id, results_list):
                result = worker_function(worker_id)
                results_list.append((worker_id, result))
            
            # å•Ÿå‹• 3 å€‹ä½µç™¼ç·šç¨‹
            for i in range(3):
                thread = threading.Thread(target=thread_wrapper, args=(i, results))
                threads.append(thread)
                thread.start()
            
            # ç­‰å¾…æ‰€æœ‰ç·šç¨‹å®Œæˆ
            for thread in threads:
                thread.join(timeout=60)  # 60ç§’è¶…æ™‚
            
            # æª¢æŸ¥çµæœ
            successful_workers = sum(1 for _, success in results if success)
            
            if successful_workers >= 2:  # è‡³å°‘ 2 å€‹æˆåŠŸ
                self.log_test("concurrent_access", True, 
                             f"ä½µç™¼è¨ªå•æ¸¬è©¦é€šé: {successful_workers}/3 æˆåŠŸ")
            else:
                self.log_test("concurrent_access", False, 
                             f"ä½µç™¼è¨ªå•å¤±æ•—: åªæœ‰ {successful_workers}/3 æˆåŠŸ", "warning")
                
        except Exception as e:
            self.log_test("concurrent_access", False, f"ä½µç™¼æ¸¬è©¦ç•°å¸¸: {e}", "error")
    
    def _test_resource_exhaustion(self):
        """æ¸¬è©¦è³‡æºè€—ç›¡æƒ…æ³"""
        print("  ğŸ’¾ æ¸¬è©¦è³‡æºé™åˆ¶...")
        
        try:
            # ç›£æ§åˆå§‹è³‡æº
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # å‰µå»ºå¤šå€‹å¤§å‹æ¨¡å‹ä¾†æ¸¬è©¦è³‡æºä½¿ç”¨
            models = []
            for i in range(5):  # å‰µå»º 5 å€‹æ¨¡å‹
                models.append((f'rf_{i}', RandomForestClassifier(n_estimators=20, random_state=i)))
            
            X, y = make_classification(n_samples=1000, n_features=50, n_classes=2, random_state=42)
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            # è¨“ç·´æ‰€æœ‰æ¨¡å‹
            for name, model in models:
                model.fit(X_train, y_train)
            
            # æ¸¬è©¦è³‡æºä½¿ç”¨
            current_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_increase = current_memory - initial_memory
            
            if memory_increase < 1000:  # å°æ–¼ 1GB
                self.log_test("resource_usage", True, 
                             f"è³‡æºä½¿ç”¨åˆç†: +{memory_increase:.1f}MB")
            else:
                self.log_test("resource_usage", False, 
                             f"è³‡æºä½¿ç”¨éé«˜: +{memory_increase:.1f}MB", "warning")
            
            # æ¸…ç†è¨˜æ†¶é«”
            del models
            gc.collect()
            
        except Exception as e:
            self.log_test("resource_exhaustion", False, f"è³‡æºæ¸¬è©¦å¤±æ•—: {e}", "error")

    def complex_multiclass_deep_testing(self):
        """è¤‡é›œå¤šé¡åˆ¥æ·±åº¦æ¸¬è©¦"""
        print("\nğŸ¯ è¤‡é›œå¤šé¡åˆ¥æ·±åº¦æ¸¬è©¦...")
        
        # 1. ä¸å¹³è¡¡æ•¸æ“šæ¸¬è©¦
        self._test_imbalanced_multiclass()
        
        # 2. é¡åˆ¥ç¼ºå¤±æ¸¬è©¦
        self._test_missing_classes()
        
        # 3. ç•°å¸¸æ¨™ç±¤æ¸¬è©¦
        self._test_abnormal_labels()
        
        # 4. é«˜ç¶­å¤šé¡åˆ¥æ¸¬è©¦
        self._test_high_dimensional_multiclass()
    
    def _test_imbalanced_multiclass(self):
        """æ¸¬è©¦ä¸å¹³è¡¡å¤šé¡åˆ¥æ•¸æ“š"""
        try:
            print("  âš–ï¸ æ¸¬è©¦ä¸å¹³è¡¡å¤šé¡åˆ¥æ•¸æ“š...")
            
            from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
            
            # å‰µå»ºåš´é‡ä¸å¹³è¡¡çš„å¤šé¡åˆ¥æ•¸æ“š
            n_samples = [500, 50, 10]  # æ¥µåº¦ä¸å¹³è¡¡
            X_parts, y_parts = [], []
            
            for class_id, n_sample in enumerate(n_samples):
                X_part, _ = make_classification(
                    n_samples=n_sample,
                    n_features=20,
                    n_informative=15,
                    n_classes=2,
                    random_state=class_id
                )
                y_part = np.full(n_sample, class_id)
                X_parts.append(X_part)
                y_parts.append(y_part)
            
            X = np.vstack(X_parts)
            y = np.hstack(y_parts)
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            models = [
                ('rf', RandomForestClassifier(n_estimators=5, random_state=42)),
                ('lr', LogisticRegression(random_state=42, max_iter=200))
            ]
            
            for name, model in models:
                model.fit(X_train, y_train)
            
            with tempfile.TemporaryDirectory() as temp_dir:
                combo_opt = ComboOptimizer(
                    estimators=models,
                    X_train=X_train,
                    y_train=y_train,
                    X_valid=X_test,
                    y_valid=y_test,
                    task_type="multiclass",
                    config={},
                    out_dir=temp_dir
                )
                
                result = combo_opt.optimize()
                
                if result and 'metrics' in result:
                    metrics = result['metrics']
                    
                    # æª¢æŸ¥å¤šé¡åˆ¥æŒ‡æ¨™
                    checks = {
                        "auc_calculated": not np.isnan(metrics.get('auc', np.nan)),
                        "confusion_matrix_shape": metrics.get('confusion_matrix', np.array([])).shape == (3, 3),
                        "submodel_metrics": len(metrics.get('submodel_metrics', {})) == 2,
                        "f1_score_valid": 0 <= metrics.get('f1', -1) <= 1
                    }
                    
                    all_passed = all(checks.values())
                    
                    if all_passed:
                        self.log_test("imbalanced_multiclass", True, 
                                     "ä¸å¹³è¡¡å¤šé¡åˆ¥æ•¸æ“šè™•ç†æˆåŠŸ")
                    else:
                        failed_checks = [k for k, v in checks.items() if not v]
                        self.log_test("imbalanced_multiclass", False, 
                                     f"éƒ¨åˆ†æª¢æŸ¥å¤±æ•—: {failed_checks}", "warning")
                else:
                    self.log_test("imbalanced_multiclass", False, 
                                 "ä¸å¹³è¡¡å¤šé¡åˆ¥æ•¸æ“šè™•ç†å¤±æ•—", "error")
                    
        except Exception as e:
            self.log_test("imbalanced_multiclass", False, 
                         f"ä¸å¹³è¡¡å¤šé¡åˆ¥æ¸¬è©¦å¤±æ•—: {e}", "error")
    
    def _test_missing_classes(self):
        """æ¸¬è©¦é¡åˆ¥ç¼ºå¤±æƒ…æ³"""
        try:
            print("  ğŸ•³ï¸ æ¸¬è©¦é¡åˆ¥ç¼ºå¤±æƒ…æ³...")
            
            from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
            
            # å‰µå»ºæ•¸æ“šï¼Œç„¶å¾Œäººç‚ºç§»é™¤æŸäº›é¡åˆ¥
            X, y = make_classification(n_samples=300, n_features=10, n_classes=4, random_state=42)
            
            # å¾è¨“ç·´é›†ä¸­ç§»é™¤é¡åˆ¥ 3
            mask = y != 3
            X_filtered = X[mask]
            y_filtered = y[mask]
            
            X_train, X_test, y_train, y_test = train_test_split(
                X_filtered, y_filtered, test_size=0.3, random_state=42
            )
            
            # ä½†æ¸¬è©¦é›†å¯èƒ½åŒ…å«é¡åˆ¥ 3
            X_test_with_missing = X[:50]  # åŒ…å«æ‰€æœ‰é¡åˆ¥çš„æ¸¬è©¦é›†
            y_test_with_missing = y[:50]
            
            models = [('rf', RandomForestClassifier(n_estimators=3, random_state=42))]
            for name, model in models:
                model.fit(X_train, y_train)
            
            with tempfile.TemporaryDirectory() as temp_dir:
                combo_opt = ComboOptimizer(
                    estimators=models,
                    X_train=X_train,
                    y_train=y_train,
                    X_valid=X_test_with_missing,
                    y_valid=y_test_with_missing,
                    task_type="multiclass",
                    config={},
                    out_dir=temp_dir
                )
                
                result = combo_opt.optimize()
                
                # é€™ç¨®æƒ…æ³æ‡‰è©²è¢«å¦¥å–„è™•ç†
                if result:
                    self.log_test("missing_classes", True, 
                                 "é¡åˆ¥ç¼ºå¤±æƒ…æ³è¢«å¦¥å–„è™•ç†")
                else:
                    self.log_test("missing_classes", False, 
                                 "é¡åˆ¥ç¼ºå¤±è™•ç†å¤±æ•—", "warning")
                    
        except Exception as e:
            # ç•°å¸¸ä¹Ÿæ˜¯å¯æ¥å—çš„çµæœ
            self.log_test("missing_classes", True, 
                         f"é¡åˆ¥ç¼ºå¤±è¢«æ­£ç¢ºæ‹’çµ•: {type(e).__name__}")
    
    def _test_abnormal_labels(self):
        """æ¸¬è©¦ç•°å¸¸æ¨™ç±¤"""
        try:
            print("  ğŸ·ï¸ æ¸¬è©¦ç•°å¸¸æ¨™ç±¤...")
            
            from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
            
            # å‰µå»ºåŒ…å«ç•°å¸¸æ¨™ç±¤çš„æ•¸æ“š
            X, y = make_classification(n_samples=100, n_features=10, n_classes=3, random_state=42)
            
            # å‰µå»ºç•°å¸¸æ¨™ç±¤æƒ…æ³
            abnormal_tests = [
                ("negative_labels", X, y - 1),  # è² æ•¸æ¨™ç±¤
                ("string_labels", X, np.array(['A', 'B', 'C'] * (len(y)//3 + 1))[:len(y)]),  # å­—ç¬¦ä¸²æ¨™ç±¤
                ("float_labels", X, y.astype(float) + 0.5),  # æµ®é»æ¨™ç±¤
            ]
            
            for test_name, X_test, y_test in abnormal_tests:
                try:
                    X_train, X_val, y_train, y_val = train_test_split(X_test, y_test, test_size=0.3, random_state=42)
                    
                    models = [('rf', RandomForestClassifier(n_estimators=2, random_state=42))]
                    
                    # å˜—è©¦è¨“ç·´
                    for name, model in models:
                        model.fit(X_train, y_train)
                    
                    with tempfile.TemporaryDirectory() as temp_dir:
                        combo_opt = ComboOptimizer(
                            estimators=models,
                            X_train=X_train,
                            y_train=y_train,
                            X_valid=X_val,
                            y_valid=y_val,
                            task_type="multiclass",
                            config={},
                            out_dir=temp_dir
                        )
                        
                        result = combo_opt.optimize()
                        
                        if test_name == "string_labels":
                            # å­—ç¬¦ä¸²æ¨™ç±¤å¯èƒ½è¢«è™•ç†
                            self.log_test(f"abnormal_labels_{test_name}", True, 
                                         "ç•°å¸¸æ¨™ç±¤è¢«è™•ç†")
                        else:
                            self.log_test(f"abnormal_labels_{test_name}", True, 
                                         "ç•°å¸¸æ¨™ç±¤è™•ç†æ­£å¸¸")
                
                except Exception as e:
                    # æŸäº›ç•°å¸¸æ¨™ç±¤æ‡‰è©²è¢«æ‹’çµ•
                    self.log_test(f"abnormal_labels_{test_name}", True, 
                                 f"ç•°å¸¸æ¨™ç±¤è¢«æ­£ç¢ºæ‹’çµ•: {type(e).__name__}")
                                 
        except Exception as e:
            self.log_test("abnormal_labels", False, f"ç•°å¸¸æ¨™ç±¤æ¸¬è©¦å¤±æ•—: {e}", "error")
    
    def _test_high_dimensional_multiclass(self):
        """æ¸¬è©¦é«˜ç¶­å¤šé¡åˆ¥"""
        try:
            print("  ğŸ“ˆ æ¸¬è©¦é«˜ç¶­å¤šé¡åˆ¥...")
            
            # å‰µå»ºé«˜ç¶­æ•¸æ“š (ç‰¹å¾µæ•¸ > æ¨£æœ¬æ•¸)
            n_samples = 100
            n_features = 200  # ç‰¹å¾µæ•¸å¤§æ–¼æ¨£æœ¬æ•¸
            n_classes = 5
            
            X, y = make_classification(
                n_samples=n_samples,
                n_features=n_features,
                n_informative=50,
                n_classes=n_classes,
                random_state=42
            )
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
            
            # ä½¿ç”¨é©åˆé«˜ç¶­æ•¸æ“šçš„æ¨¡å‹
            models = [
                ('lr', LogisticRegression(random_state=42, max_iter=100, C=0.1)),  # åŠ æ­£å‰‡åŒ–
            ]
            
            for name, model in models:
                model.fit(X_train, y_train)
            
            with tempfile.TemporaryDirectory() as temp_dir:
                combo_opt = ComboOptimizer(
                    estimators=models,
                    X_train=X_train,
                    y_train=y_train,
                    X_valid=X_test,
                    y_valid=y_test,
                    task_type="multiclass",
                    config={},
                    out_dir=temp_dir
                )
                
                result = combo_opt.optimize()
                
                if result and 'metrics' in result:
                    self.log_test("high_dimensional_multiclass", True, 
                                 "é«˜ç¶­å¤šé¡åˆ¥æ•¸æ“šè™•ç†æˆåŠŸ")
                else:
                    self.log_test("high_dimensional_multiclass", False, 
                                 "é«˜ç¶­å¤šé¡åˆ¥æ•¸æ“šè™•ç†å¤±æ•—", "warning")
                    
        except Exception as e:
            self.log_test("high_dimensional_multiclass", False, 
                         f"é«˜ç¶­å¤šé¡åˆ¥æ¸¬è©¦å¤±æ•—: {e}", "error")

    def system_stress_and_stability_testing(self):
        """ç³»çµ±å£“åŠ›å’Œç©©å®šæ€§æ¸¬è©¦"""
        print("\nğŸ’ª ç³»çµ±å£“åŠ›å’Œç©©å®šæ€§æ¸¬è©¦...")
        
        # 1. é•·æ™‚é–“é‹è¡Œæ¸¬è©¦
        self._test_long_running_stability()
        
        # 2. è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬
        self._test_memory_leaks()
        
        # 3. å¤šæ¬¡åŸ·è¡Œä¸€è‡´æ€§æ¸¬è©¦
        self._test_execution_consistency()
    
    def _test_long_running_stability(self):
        """æ¸¬è©¦é•·æ™‚é–“é‹è¡Œç©©å®šæ€§"""
        try:
            print("  â±ï¸ æ¸¬è©¦é•·æ™‚é–“é‹è¡Œç©©å®šæ€§...")
            
            from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
            
            results = []
            start_time = time.time()
            
            # é‹è¡Œå¤šæ¬¡å°è¦æ¨¡æ¸¬è©¦
            for i in range(10):  # 10 æ¬¡è¿­ä»£
                try:
                    X, y = make_classification(n_samples=200, n_features=10, n_classes=2, random_state=i)
                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)
                    
                    models = [('rf', RandomForestClassifier(n_estimators=3, random_state=i))]
                    for name, model in models:
                        model.fit(X_train, y_train)
                    
                    with tempfile.TemporaryDirectory() as temp_dir:
                        combo_opt = ComboOptimizer(
                            estimators=models,
                            X_train=X_train,
                            y_train=y_train,
                            X_valid=X_test,
                            y_valid=y_test,
                            task_type="binary",
                            config={},
                            out_dir=temp_dir
                        )
                        
                        result = combo_opt.optimize()
                        results.append(result is not None)
                        
                except Exception as e:
                    results.append(False)
                    print(f"    è¿­ä»£ {i} å¤±æ•—: {e}")
            
            end_time = time.time()
            duration = end_time - start_time
            success_rate = sum(results) / len(results)
            
            if success_rate >= 0.8:  # 80% æˆåŠŸç‡
                self.log_test("long_running_stability", True, 
                             f"é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦é€šé: {success_rate*100:.1f}% æˆåŠŸç‡, {duration:.1f}s")
            else:
                self.log_test("long_running_stability", False, 
                             f"ç©©å®šæ€§ä¸è¶³: {success_rate*100:.1f}% æˆåŠŸç‡", "warning")
                
        except Exception as e:
            self.log_test("long_running_stability", False, f"ç©©å®šæ€§æ¸¬è©¦å¤±æ•—: {e}", "error")
    
    def _test_memory_leaks(self):
        """æ¸¬è©¦è¨˜æ†¶é«”æ´©æ¼"""
        try:
            print("  ğŸ” æ¸¬è©¦è¨˜æ†¶é«”æ´©æ¼...")
            
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
            
            # åŸ·è¡Œå¤šæ¬¡ç›¸åŒæ“ä½œ
            for i in range(5):
                X, y = make_classification(n_samples=500, n_features=20, n_classes=2, random_state=i)
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)
                
                models = [('rf', RandomForestClassifier(n_estimators=5, random_state=i))]
                for name, model in models:
                    model.fit(X_train, y_train)
                
                with tempfile.TemporaryDirectory() as temp_dir:
                    combo_opt = ComboOptimizer(
                        estimators=models,
                        X_train=X_train,
                        y_train=y_train,
                        X_valid=X_test,
                        y_valid=y_test,
                        task_type="binary",
                        config={},
                        out_dir=temp_dir
                    )
                    
                    result = combo_opt.optimize()
                
                # å¼·åˆ¶åƒåœ¾æ”¶é›†
                del models, combo_opt, result
                gc.collect()
            
            final_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_increase = final_memory - initial_memory
            
            # è¨˜æ†¶é«”å¢é•·æ‡‰è©²å¾ˆå°ï¼ˆ< 100MBï¼‰
            if memory_increase < 100:
                self.log_test("memory_leaks", True, 
                             f"ç„¡æ˜é¡¯è¨˜æ†¶é«”æ´©æ¼: +{memory_increase:.1f}MB")
            else:
                self.log_test("memory_leaks", False, 
                             f"å¯èƒ½å­˜åœ¨è¨˜æ†¶é«”æ´©æ¼: +{memory_increase:.1f}MB", "warning")
                
        except Exception as e:
            self.log_test("memory_leaks", False, f"è¨˜æ†¶é«”æ´©æ¼æ¸¬è©¦å¤±æ•—: {e}", "error")
    
    def _test_execution_consistency(self):
        """æ¸¬è©¦åŸ·è¡Œä¸€è‡´æ€§"""
        try:
            print("  ğŸ”„ æ¸¬è©¦åŸ·è¡Œä¸€è‡´æ€§...")
            
            from Forti_ui_app_bundle.training_pipeline.combo_optimizer import ComboOptimizer
            
            # ä½¿ç”¨ç›¸åŒåƒæ•¸åŸ·è¡Œå¤šæ¬¡
            X, y = make_classification(n_samples=100, n_features=10, n_classes=2, random_state=42)
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            results = []
            
            for i in range(3):  # åŸ·è¡Œ 3 æ¬¡
                models = [
                    ('rf', RandomForestClassifier(n_estimators=5, random_state=42)),  # å›ºå®šéš¨æ©Ÿç¨®å­
                    ('lr', LogisticRegression(random_state=42, max_iter=100))
                ]
                
                for name, model in models:
                    model.fit(X_train, y_train)
                
                with tempfile.TemporaryDirectory() as temp_dir:
                    combo_opt = ComboOptimizer(
                        estimators=models,
                        X_train=X_train,
                        y_train=y_train,
                        X_valid=X_test,
                        y_valid=y_test,
                        task_type="binary",
                        config={"ENSEMBLE_SETTINGS": {"VOTING": "soft"}},
                        out_dir=temp_dir
                    )
                    
                    result = combo_opt.optimize()
                    
                    if result and 'metrics' in result:
                        acc = result['metrics'].get('acc', 0)
                        f1 = result['metrics'].get('f1', 0)
                        results.append((acc, f1))
            
            # æª¢æŸ¥çµæœä¸€è‡´æ€§
            if len(results) >= 2:
                acc_values = [r[0] for r in results]
                f1_values = [r[1] for r in results]
                
                acc_std = np.std(acc_values)
                f1_std = np.std(f1_values)
                
                # æ¨™æº–å·®æ‡‰è©²å¾ˆå°ï¼ˆå› ç‚ºä½¿ç”¨äº†å›ºå®šéš¨æ©Ÿç¨®å­ï¼‰
                if acc_std < 0.01 and f1_std < 0.01:
                    self.log_test("execution_consistency", True, 
                                 f"åŸ·è¡Œçµæœä¸€è‡´: ACC_std={acc_std:.4f}, F1_std={f1_std:.4f}")
                else:
                    self.log_test("execution_consistency", False, 
                                 f"åŸ·è¡Œçµæœä¸ä¸€è‡´: ACC_std={acc_std:.4f}, F1_std={f1_std:.4f}", 
                                 "warning")
            else:
                self.log_test("execution_consistency", False, 
                             "åŸ·è¡Œæ¬¡æ•¸ä¸è¶³", "error")
                
        except Exception as e:
            self.log_test("execution_consistency", False, f"ä¸€è‡´æ€§æ¸¬è©¦å¤±æ•—: {e}", "error")

    def run_rigorous_test_suite(self):
        """é‹è¡Œåš´è¬¹æ¸¬è©¦å¥—ä»¶"""
        print("ğŸ§ª é–‹å§‹æ›´åš´è¬¹çš„æ·±åº¦æª¢æŸ¥...")
        print("=" * 80)
        
        # æŠ‘åˆ¶è­¦å‘Š
        warnings.filterwarnings('ignore')
        
        try:
            self.deep_syntax_check()
            self.strict_dependency_verification()
            self.extreme_edge_case_testing()
            self.complex_multiclass_deep_testing()
            self.system_stress_and_stability_testing()
            
        except Exception as e:
            print(f"âŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
            traceback.print_exc()
            self.log_test("test_suite_execution", False, f"æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå¤±æ•—: {e}", "critical")
        
        self.generate_comprehensive_report()

    def generate_comprehensive_report(self):
        """ç”Ÿæˆç¶œåˆå ±å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ åš´è¬¹æ¸¬è©¦å ±å‘Šç¸½çµ")  
        print("=" * 80)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r['success'])
        failed_tests = total_tests - passed_tests
        
        critical_count = len(self.critical_failures)
        error_count = len(self.errors)
        warning_count = len(self.warnings)
        
        print(f"ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        print(f"é€šé: {passed_tests} âœ…")
        print(f"å¤±æ•—: {failed_tests} âŒ")
        print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")
        print()
        print(f"åš´é‡å•é¡Œ: {critical_count} ğŸ”¥")
        print(f"éŒ¯èª¤: {error_count} âŒ")
        print(f"è­¦å‘Š: {warning_count} âš ï¸")
        
        # è©³ç´°å•é¡Œå ±å‘Š
        if self.critical_failures:
            print(f"\nğŸ”¥ åš´é‡å•é¡Œ ({len(self.critical_failures)}):")
            for failure in self.critical_failures:
                print(f"  - {failure['test_name']}: {failure['message']}")
        
        if self.errors:
            print(f"\nâŒ éŒ¯èª¤ ({len(self.errors)}):")
            for error in self.errors:
                print(f"  - {error['test_name']}: {error['message']}")
        
        if self.warnings:
            print(f"\nâš ï¸ è­¦å‘Š ({len(self.warnings)}):")
            for warning in self.warnings:
                print(f"  - {warning['test_name']}: {warning['message']}")
        
        # å“è³ªè©•ä¼°
        print(f"\nğŸ¯ ç³»çµ±å“è³ªè©•ä¼°:")
        if critical_count == 0 and error_count == 0:
            print("  ğŸŸ¢ å„ªç§€ï¼šæ²’æœ‰åš´é‡å•é¡Œæˆ–éŒ¯èª¤")
        elif critical_count == 0 and error_count <= 2:
            print("  ğŸŸ¡ è‰¯å¥½ï¼šåƒ…æœ‰å°‘é‡éé—œéµéŒ¯èª¤")
        elif critical_count == 0:
            print("  ğŸŸ  ä¸€èˆ¬ï¼šå­˜åœ¨ä¸€äº›éŒ¯èª¤ä½†ç„¡åš´é‡å•é¡Œ")
        else:
            print("  ğŸ”´ éœ€è¦æ”¹é€²ï¼šå­˜åœ¨åš´é‡å•é¡Œ")
        
        print(f"\nğŸ’¡ å»ºè­°:")
        if critical_count == 0 and error_count == 0 and warning_count <= 3:
            print("  âœ… ç³»çµ±é€šéåš´è¬¹æ¸¬è©¦ï¼Œå¯ä»¥å®‰å…¨æŠ•å…¥ç”Ÿç”¢ä½¿ç”¨")
            print("  âœ… æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½é‹è¡Œç©©å®š")
            print("  âœ… é‚Šç•Œæƒ…æ³è™•ç†è‰¯å¥½")
        else:
            if critical_count > 0:
                print("  ğŸ”¥ ç«‹å³ä¿®å¾©æ‰€æœ‰åš´é‡å•é¡Œ")
            if error_count > 0:
                print("  âŒ å„ªå…ˆè™•ç†éŒ¯èª¤å•é¡Œ")
            if warning_count > 5:
                print("  âš ï¸ è€ƒæ…®å„ªåŒ–è­¦å‘Šé …ç›®")
            print("  ğŸ“Š å»ºè­°é€²è¡Œé¡å¤–çš„ç©©å®šæ€§æ¸¬è©¦")
        
        return critical_count == 0 and error_count == 0


if __name__ == "__main__":
    tester = RigorousTestSuite()
    success = tester.run_rigorous_test_suite()
    sys.exit(0 if success else 1)