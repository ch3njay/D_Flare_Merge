"""è³‡æ–™æª¢æŸ¥å·¥å…· - å”åŠ©ä½¿ç”¨è€…åˆ†æè³‡æ–™çµæ§‹ä¸¦è­˜åˆ¥å¯èƒ½çš„ç›®æ¨™æ¬„ä½"""
import pandas as pd
import sys
from typing import List, Dict, Any


class DataInspector:
    """è³‡æ–™æª¢æŸ¥èˆ‡åˆ†æå·¥å…·"""
    
    def __init__(self, csv_path: str):
        """
        åˆå§‹åŒ–è³‡æ–™æª¢æŸ¥å™¨
        
        Args:
            csv_path: CSV æª”æ¡ˆè·¯å¾‘
        """
        self.csv_path = csv_path
        self.df = None
        
    def load_and_inspect(self) -> Dict[str, Any]:
        """è¼‰å…¥ä¸¦æª¢æŸ¥è³‡æ–™"""
        print(f"ğŸ“‚ è¼‰å…¥è³‡æ–™ï¼š{self.csv_path}")
        
        try:
            self.df = pd.read_csv(self.csv_path, encoding='utf-8-sig')
        except Exception as e:
            print(f"âŒ UTF-8 ç·¨ç¢¼å¤±æ•—ï¼Œå˜—è©¦å…¶ä»–ç·¨ç¢¼...")
            try:
                self.df = pd.read_csv(self.csv_path, encoding='cp950')
            except Exception as e2:
                print(f"âŒ è®€å–å¤±æ•—ï¼š{e2}")
                return {"success": False, "error": str(e2)}
        
        print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.df)} ç­†è³‡æ–™ï¼Œ{len(self.df.columns)} å€‹æ¬„ä½\n")
        
        # åŸ·è¡Œå®Œæ•´åˆ†æ
        analysis = {
            "success": True,
            "basic_info": self._get_basic_info(),
            "column_analysis": self._analyze_columns(),
            "target_candidates": self._find_target_candidates(),
            "recommendations": self._generate_recommendations()
        }
        
        return analysis
    
    def _get_basic_info(self) -> Dict[str, Any]:
        """å–å¾—åŸºæœ¬è³‡æ–™è³‡è¨Š"""
        return {
            "rows": len(self.df),
            "columns": len(self.df.columns),
            "column_names": list(self.df.columns),
            "memory_usage": f"{self.df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB"
        }
    
    def _analyze_columns(self) -> List[Dict[str, Any]]:
        """åˆ†ææ¯å€‹æ¬„ä½çš„ç‰¹æ€§"""
        column_info = []
        
        for col in self.df.columns:
            info = {
                "name": col,
                "dtype": str(self.df[col].dtype),
                "unique_count": self.df[col].nunique(),
                "null_count": self.df[col].isnull().sum(),
                "null_percentage": f"{self.df[col].isnull().sum() / len(self.df) * 100:.2f}%"
            }
            
            # å¦‚æœæ˜¯æ•¸å€¼å‹ï¼Œæä¾›çµ±è¨ˆè³‡è¨Š
            if pd.api.types.is_numeric_dtype(self.df[col]):
                info["min"] = self.df[col].min()
                info["max"] = self.df[col].max()
                info["mean"] = f"{self.df[col].mean():.2f}"
                info["is_numeric"] = True
            else:
                info["is_numeric"] = False
                # é¡¯ç¤ºå‰å¹¾å€‹å”¯ä¸€å€¼ï¼ˆå¦‚æœä¸å¤ªå¤šï¼‰
                if info["unique_count"] <= 10:
                    info["sample_values"] = list(self.df[col].unique()[:5])
            
            column_info.append(info)
        
        return column_info
    
    def _find_target_candidates(self) -> List[Dict[str, Any]]:
        """å°‹æ‰¾å¯èƒ½çš„ç›®æ¨™æ¬„ä½å€™é¸"""
        candidates = []
        
        # å¸¸è¦‹æ¨™ç±¤æ¬„ä½åç¨±
        common_names = [
            'label', 'target', 'class', 'y', 'attack_type', 'is_attack',
            'category', 'classification', 'type', 'severity', 'crlevel',
            'priority', 'risk_level', 'threat_level', 'status'
        ]
        
        for col in self.df.columns:
            reasons = []
            score = 0
            
            # 1. æª¢æŸ¥åç¨±æ˜¯å¦åŒ¹é…å¸¸è¦‹æ¨™ç±¤åç¨±
            if col.lower() in common_names:
                reasons.append(f"æ¬„ä½åç¨± '{col}' æ˜¯å¸¸è¦‹çš„æ¨™ç±¤æ¬„ä½åç¨±")
                score += 50
            
            # 2. æª¢æŸ¥æ˜¯å¦ç‚ºæ•¸å€¼å‹ä¸”å”¯ä¸€å€¼è¼ƒå°‘
            if pd.api.types.is_numeric_dtype(self.df[col]):
                unique_count = self.df[col].nunique()
                total_count = len(self.df)
                unique_ratio = unique_count / total_count
                
                if unique_count < 20:
                    reasons.append(f"å”¯ä¸€å€¼æ•¸é‡å°‘ï¼ˆ{unique_count} å€‹ï¼‰")
                    score += 30
                
                if unique_ratio < 0.01:
                    reasons.append(f"å”¯ä¸€å€¼æ¯”ä¾‹ä½ï¼ˆ{unique_ratio*100:.4f}%ï¼‰")
                    score += 20
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºäºŒå…ƒåˆ†é¡ï¼ˆåªæœ‰ 0/1 æˆ–é¡ä¼¼å€¼ï¼‰
                unique_values = set(self.df[col].dropna().unique())
                if unique_values.issubset({0, 1}) or unique_values.issubset({'0', '1'}):
                    reasons.append("çœ‹èµ·ä¾†æ˜¯äºŒå…ƒåˆ†é¡ï¼ˆ0/1ï¼‰")
                    score += 40
            
            # 3. å¦‚æœåˆ†æ•¸è¶³å¤ é«˜ï¼ŒåŠ å…¥å€™é¸æ¸…å–®
            if score >= 30:
                value_counts = self.df[col].value_counts().to_dict()
                candidates.append({
                    "column": col,
                    "score": score,
                    "reasons": reasons,
                    "unique_count": self.df[col].nunique(),
                    "value_distribution": value_counts
                })
        
        # æŒ‰åˆ†æ•¸æ’åº
        candidates.sort(key=lambda x: x["score"], reverse=True)
        
        return candidates
    
    def _generate_recommendations(self) -> List[str]:
        """ç”¢ç”Ÿå»ºè­°"""
        recommendations = []
        
        candidates = self._find_target_candidates()
        
        if candidates:
            top_candidate = candidates[0]
            recommendations.append(
                f"âœ… å»ºè­°ä½¿ç”¨ '{top_candidate['column']}' ä½œç‚ºç›®æ¨™æ¬„ä½ "
                f"(ä¿¡å¿ƒåˆ†æ•¸: {top_candidate['score']}/100)"
            )
            recommendations.append(
                f"   åŸå› ï¼š{'; '.join(top_candidate['reasons'])}"
            )
            
            # å¦‚æœæœ‰å¤šå€‹å€™é¸
            if len(candidates) > 1:
                recommendations.append("\nå…¶ä»–å¯èƒ½çš„ç›®æ¨™æ¬„ä½ï¼š")
                for cand in candidates[1:3]:  # é¡¯ç¤ºå‰ 2 å€‹æ›¿ä»£é¸é …
                    recommendations.append(
                        f"  - {cand['column']} (åˆ†æ•¸: {cand['score']}/100)"
                    )
        else:
            recommendations.append(
                "âŒ æœªæ‰¾åˆ°æ˜é¡¯çš„ç›®æ¨™æ¬„ä½å€™é¸"
            )
            recommendations.append(
                "ğŸ’¡ æ‚¨å¯èƒ½éœ€è¦ï¼š\n"
                "   1. æ‰‹å‹•æ–°å¢æ¨™ç±¤æ¬„ä½ï¼ˆä¾‹å¦‚ 'is_attack' æˆ– 'label'ï¼‰\n"
                "   2. ä½¿ç”¨ç¾æœ‰æ¬„ä½é€²è¡Œè½‰æ›ï¼ˆä¾‹å¦‚æ ¹æ“šæŸäº›æ¢ä»¶å»ºç«‹æ¨™ç±¤ï¼‰\n"
                "   3. ä½¿ç”¨ç„¡ç›£ç£å­¸ç¿’æ–¹æ³•ï¼ˆç•°å¸¸åµæ¸¬ç­‰ï¼‰"
            )
        
        # æª¢æŸ¥è³‡æ–™å“è³ªå•é¡Œ
        null_columns = [col for col in self.df.columns 
                       if self.df[col].isnull().sum() > len(self.df) * 0.5]
        if null_columns:
            recommendations.append(
                f"\nâš ï¸ ä»¥ä¸‹æ¬„ä½ç¼ºå¤±å€¼è¶…é 50%ï¼Œå»ºè­°ç§»é™¤ï¼š\n   "
                f"{', '.join(null_columns)}"
            )
        
        return recommendations
    
    def print_report(self, analysis: Dict[str, Any]):
        """å°å‡ºå®Œæ•´çš„åˆ†æå ±å‘Š"""
        if not analysis["success"]:
            print(f"âŒ åˆ†æå¤±æ•—ï¼š{analysis['error']}")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š è³‡æ–™åˆ†æå ±å‘Š")
        print("="*60)
        
        # åŸºæœ¬è³‡è¨Š
        info = analysis["basic_info"]
        print(f"\nğŸ“ˆ åŸºæœ¬è³‡è¨Šï¼š")
        print(f"  - è³‡æ–™ç­†æ•¸ï¼š{info['rows']:,}")
        print(f"  - æ¬„ä½æ•¸é‡ï¼š{info['columns']}")
        print(f"  - è¨˜æ†¶é«”ç”¨é‡ï¼š{info['memory_usage']}")
        
        # æ¬„ä½åˆ†æ
        print(f"\nğŸ“‹ æ¬„ä½è©³ç´°åˆ†æï¼š")
        print(f"{'æ¬„ä½åç¨±':<30} {'å‹åˆ¥':<10} {'å”¯ä¸€å€¼':<10} {'ç¼ºå¤±å€¼':<10}")
        print("-" * 60)
        for col_info in analysis["column_analysis"]:
            print(f"{col_info['name']:<30} "
                  f"{col_info['dtype']:<10} "
                  f"{col_info['unique_count']:<10} "
                  f"{col_info['null_percentage']:<10}")
        
        # ç›®æ¨™æ¬„ä½å€™é¸
        print(f"\nğŸ¯ å¯èƒ½çš„ç›®æ¨™æ¬„ä½å€™é¸ï¼š")
        candidates = analysis["target_candidates"]
        if candidates:
            for i, cand in enumerate(candidates[:3], 1):
                print(f"\n{i}. {cand['column']} (ä¿¡å¿ƒåˆ†æ•¸: {cand['score']}/100)")
                print(f"   åŸå› ï¼š")
                for reason in cand['reasons']:
                    print(f"     - {reason}")
                print(f"   å”¯ä¸€å€¼æ•¸é‡ï¼š{cand['unique_count']}")
                print(f"   å€¼åˆ†ä½ˆï¼š{cand['value_distribution']}")
        else:
            print("  âŒ æœªæ‰¾åˆ°æ˜é¡¯çš„ç›®æ¨™æ¬„ä½å€™é¸")
        
        # å»ºè­°
        print(f"\nğŸ’¡ å»ºè­°ï¼š")
        for rec in analysis["recommendations"]:
            print(f"  {rec}")
        
        print("\n" + "="*60)
        
    def export_report(self, analysis: Dict[str, Any], output_path: str = None):
        """åŒ¯å‡ºåˆ†æå ±å‘Šç‚º JSON"""
        if output_path is None:
            output_path = self.csv_path.replace('.csv', '_analysis.json')
        
        import json
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ åˆ†æå ±å‘Šå·²åŒ¯å‡ºè‡³ï¼š{output_path}")


def main():
    """ä¸»ç¨‹å¼"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹å¼ï¼špython data_inspector.py <csv_file_path>")
        print("ç¯„ä¾‹ï¼špython data_inspector.py C:\\Users\\U02020\\AppData\\Local\\Temp\\preprocessed_data.csv")
        return
    
    csv_path = sys.argv[1]
    
    inspector = DataInspector(csv_path)
    analysis = inspector.load_and_inspect()
    inspector.print_report(analysis)
    
    # è©¢å•æ˜¯å¦åŒ¯å‡ºå ±å‘Š
    export = input("\næ˜¯å¦è¦åŒ¯å‡ºåˆ†æå ±å‘Šç‚º JSONï¼Ÿ(y/n): ")
    if export.lower() == 'y':
        inspector.export_report(analysis)


if __name__ == "__main__":
    main()
